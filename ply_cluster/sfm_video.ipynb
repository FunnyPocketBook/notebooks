{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "from plyfile import PlyData\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R, Slerp\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ply(file_path):\n",
    "    plydata = PlyData.read(file_path)\n",
    "    x = plydata['vertex']['x']\n",
    "    y = plydata['vertex']['y']\n",
    "    z = plydata['vertex']['z']\n",
    "    if 'red' in plydata['vertex']:\n",
    "        r = plydata['vertex']['red']\n",
    "        g = plydata['vertex']['green']\n",
    "        b = plydata['vertex']['blue']\n",
    "        colors = np.array([r, g, b]).T\n",
    "    else:\n",
    "        colors = None\n",
    "    if 'nx' in plydata['vertex']:\n",
    "        nx = plydata['vertex']['nx']\n",
    "        ny = plydata['vertex']['ny']\n",
    "        nz = plydata['vertex']['nz']\n",
    "        normals = np.array([nx, ny, nz]).T\n",
    "    else:\n",
    "        normals = None\n",
    "    points = np.array([x, y, z]).T\n",
    "    print(f\"Number of points: {points.shape[0]}\")\n",
    "    return points, colors, normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (C) 2023, Inria\n",
    "# GRAPHDECO research group, https://team.inria.fr/graphdeco\n",
    "# All rights reserved.\n",
    "#\n",
    "# This software is free for non-commercial, research and evaluation use \n",
    "# under the terms of the LICENSE.md file.\n",
    "#\n",
    "# For inquiries contact  george.drettakis@inria.fr\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import struct\n",
    "\n",
    "CameraModel = collections.namedtuple(\n",
    "    \"CameraModel\", [\"model_id\", \"model_name\", \"num_params\"])\n",
    "Camera = collections.namedtuple(\n",
    "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"])\n",
    "BaseImage = collections.namedtuple(\n",
    "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
    "Point3D = collections.namedtuple(\n",
    "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"])\n",
    "CAMERA_MODELS = {\n",
    "    CameraModel(model_id=0, model_name=\"SIMPLE_PINHOLE\", num_params=3),\n",
    "    CameraModel(model_id=1, model_name=\"PINHOLE\", num_params=4),\n",
    "    CameraModel(model_id=2, model_name=\"SIMPLE_RADIAL\", num_params=4),\n",
    "    CameraModel(model_id=3, model_name=\"RADIAL\", num_params=5),\n",
    "    CameraModel(model_id=4, model_name=\"OPENCV\", num_params=8),\n",
    "    CameraModel(model_id=5, model_name=\"OPENCV_FISHEYE\", num_params=8),\n",
    "    CameraModel(model_id=6, model_name=\"FULL_OPENCV\", num_params=12),\n",
    "    CameraModel(model_id=7, model_name=\"FOV\", num_params=5),\n",
    "    CameraModel(model_id=8, model_name=\"SIMPLE_RADIAL_FISHEYE\", num_params=4),\n",
    "    CameraModel(model_id=9, model_name=\"RADIAL_FISHEYE\", num_params=5),\n",
    "    CameraModel(model_id=10, model_name=\"THIN_PRISM_FISHEYE\", num_params=12)\n",
    "}\n",
    "CAMERA_MODEL_IDS = dict([(camera_model.model_id, camera_model)\n",
    "                         for camera_model in CAMERA_MODELS])\n",
    "CAMERA_MODEL_NAMES = dict([(camera_model.model_name, camera_model)\n",
    "                           for camera_model in CAMERA_MODELS])\n",
    "\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "def rotmat2qvec(R):\n",
    "    Rxx, Ryx, Rzx, Rxy, Ryy, Rzy, Rxz, Ryz, Rzz = R.flat\n",
    "    K = np.array([\n",
    "        [Rxx - Ryy - Rzz, 0, 0, 0],\n",
    "        [Ryx + Rxy, Ryy - Rxx - Rzz, 0, 0],\n",
    "        [Rzx + Rxz, Rzy + Ryz, Rzz - Rxx - Ryy, 0],\n",
    "        [Ryz - Rzy, Rzx - Rxz, Rxy - Ryx, Rxx + Ryy + Rzz]]) / 3.0\n",
    "    eigvals, eigvecs = np.linalg.eigh(K)\n",
    "    qvec = eigvecs[[3, 0, 1, 2], np.argmax(eigvals)]\n",
    "    if qvec[0] < 0:\n",
    "        qvec *= -1\n",
    "    return qvec\n",
    "\n",
    "class Image(BaseImage):\n",
    "    def qvec2rotmat(self):\n",
    "        return qvec2rotmat(self.qvec)\n",
    "\n",
    "def read_next_bytes(fid, num_bytes, format_char_sequence, endian_character=\"<\"):\n",
    "    \"\"\"Read and unpack the next bytes from a binary file.\n",
    "    :param fid:\n",
    "    :param num_bytes: Sum of combination of {2, 4, 8}, e.g. 2, 6, 16, 30, etc.\n",
    "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
    "    :param endian_character: Any of {@, =, <, >, !}\n",
    "    :return: Tuple of read and unpacked values.\n",
    "    \"\"\"\n",
    "    data = fid.read(num_bytes)\n",
    "    return struct.unpack(endian_character + format_char_sequence, data)\n",
    "\n",
    "def read_points3D_text(path):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DText(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DText(const std::string& path)\n",
    "    \"\"\"\n",
    "    xyzs = None\n",
    "    rgbs = None\n",
    "    errors = None\n",
    "    num_points = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                num_points += 1\n",
    "\n",
    "\n",
    "    xyzs = np.empty((num_points, 3))\n",
    "    rgbs = np.empty((num_points, 3))\n",
    "    errors = np.empty((num_points, 1))\n",
    "    count = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
    "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
    "                error = np.array(float(elems[7]))\n",
    "                xyzs[count] = xyz\n",
    "                rgbs[count] = rgb\n",
    "                errors[count] = error\n",
    "                count += 1\n",
    "\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_points3D_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DBinary(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_points = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "\n",
    "        xyzs = np.empty((num_points, 3))\n",
    "        rgbs = np.empty((num_points, 3))\n",
    "        errors = np.empty((num_points, 1))\n",
    "\n",
    "        for p_id in range(num_points):\n",
    "            binary_point_line_properties = read_next_bytes(\n",
    "                fid, num_bytes=43, format_char_sequence=\"QdddBBBd\")\n",
    "            xyz = np.array(binary_point_line_properties[1:4])\n",
    "            rgb = np.array(binary_point_line_properties[4:7])\n",
    "            error = np.array(binary_point_line_properties[7])\n",
    "            track_length = read_next_bytes(\n",
    "                fid, num_bytes=8, format_char_sequence=\"Q\")[0]\n",
    "            track_elems = read_next_bytes(\n",
    "                fid, num_bytes=8*track_length,\n",
    "                format_char_sequence=\"ii\"*track_length)\n",
    "            xyzs[p_id] = xyz\n",
    "            rgbs[p_id] = rgb\n",
    "            errors[p_id] = error\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_intrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                camera_id = int(elems[0])\n",
    "                model = elems[1]\n",
    "                assert model == \"PINHOLE\", \"While the loader support other types, the rest of the code assumes PINHOLE\"\n",
    "                width = int(elems[2])\n",
    "                height = int(elems[3])\n",
    "                params = np.array(tuple(map(float, elems[4:])))\n",
    "                cameras[camera_id] = Camera(id=camera_id, model=model,\n",
    "                                            width=width, height=height,\n",
    "                                            params=params)\n",
    "    return cameras\n",
    "\n",
    "def read_extrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadImagesBinary(const std::string& path)\n",
    "        void Reconstruction::WriteImagesBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_reg_images = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_reg_images):\n",
    "            binary_image_properties = read_next_bytes(\n",
    "                fid, num_bytes=64, format_char_sequence=\"idddddddi\")\n",
    "            image_id = binary_image_properties[0]\n",
    "            qvec = np.array(binary_image_properties[1:5])\n",
    "            tvec = np.array(binary_image_properties[5:8])\n",
    "            camera_id = binary_image_properties[8]\n",
    "            image_name = \"\"\n",
    "            current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            while current_char != b\"\\x00\":   # look for the ASCII 0 entry\n",
    "                image_name += current_char.decode(\"utf-8\")\n",
    "                current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            num_points2D = read_next_bytes(fid, num_bytes=8,\n",
    "                                           format_char_sequence=\"Q\")[0]\n",
    "            x_y_id_s = read_next_bytes(fid, num_bytes=24*num_points2D,\n",
    "                                       format_char_sequence=\"ddq\"*num_points2D)\n",
    "            xys = np.column_stack([tuple(map(float, x_y_id_s[0::3])),\n",
    "                                   tuple(map(float, x_y_id_s[1::3]))])\n",
    "            point3D_ids = np.array(tuple(map(int, x_y_id_s[2::3])))\n",
    "            images[image_id] = Image(\n",
    "                id=image_id, qvec=qvec, tvec=tvec,\n",
    "                camera_id=camera_id, name=image_name,\n",
    "                xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_intrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::WriteCamerasBinary(const std::string& path)\n",
    "        void Reconstruction::ReadCamerasBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_cameras = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_cameras):\n",
    "            camera_properties = read_next_bytes(\n",
    "                fid, num_bytes=24, format_char_sequence=\"iiQQ\")\n",
    "            camera_id = camera_properties[0]\n",
    "            model_id = camera_properties[1]\n",
    "            model_name = CAMERA_MODEL_IDS[camera_properties[1]].model_name\n",
    "            width = camera_properties[2]\n",
    "            height = camera_properties[3]\n",
    "            num_params = CAMERA_MODEL_IDS[model_id].num_params\n",
    "            params = read_next_bytes(fid, num_bytes=8*num_params,\n",
    "                                     format_char_sequence=\"d\"*num_params)\n",
    "            cameras[camera_id] = Camera(id=camera_id,\n",
    "                                        model=model_name,\n",
    "                                        width=width,\n",
    "                                        height=height,\n",
    "                                        params=np.array(params))\n",
    "        assert len(cameras) == num_cameras\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def read_extrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
    "                                       tuple(map(float, elems[1::3]))])\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id, qvec=qvec, tvec=tvec,\n",
    "                    camera_id=camera_id, name=image_name,\n",
    "                    xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_colmap_bin_array(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_dense.py\n",
    "\n",
    "    :param path: path to the colmap binary file.\n",
    "    :return: nd array with the floating point values in the value\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as fid:\n",
    "        width, height, channels = np.genfromtxt(fid, delimiter=\"&\", max_rows=1,\n",
    "                                                usecols=(0, 1, 2), dtype=int)\n",
    "        fid.seek(0)\n",
    "        num_delimiter = 0\n",
    "        byte = fid.read(1)\n",
    "        while True:\n",
    "            if byte == b\"&\":\n",
    "                num_delimiter += 1\n",
    "                if num_delimiter >= 3:\n",
    "                    break\n",
    "            byte = fid.read(1)\n",
    "        array = np.fromfile(fid, np.float32)\n",
    "    array = array.reshape((width, height, channels), order=\"F\")\n",
    "    return np.transpose(array, (1, 0, 2)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(points_3d, camera_intrinsics, extrinsics):\n",
    "    \"\"\"\n",
    "    Project 3D points onto a 2D image plane using camera intrinsics and extrinsics.\n",
    "    \n",
    "    Parameters:\n",
    "    - points_3d: np.ndarray - Array of 3D points (N, 3).\n",
    "    - camera_intrinsics: Camera - The camera intrinsics (e.g., focal length, principal point).\n",
    "    - extrinsics: np.ndarray - 4x4 extrinsic matrix (rotation and translation).\n",
    "\n",
    "    Returns:\n",
    "    - projected_points: np.ndarray - 2D projected points in image space.\n",
    "    - mask: np.ndarray - Boolean array indicating which points are in front of the camera.\n",
    "    \"\"\"\n",
    "    # Convert points to homogeneous coordinates\n",
    "    points_homogeneous = np.hstack((points_3d, np.ones((points_3d.shape[0], 1))))\n",
    "    \n",
    "    # Transform 3D points to the camera coordinate system\n",
    "    points_camera = (extrinsics @ points_homogeneous.T).T\n",
    "    points_camera = points_camera[:, :3]\n",
    "\n",
    "    # Filter points in front of the camera\n",
    "    mask = points_camera[:, 2] > 0  # Keep points with positive Z\n",
    "    points_camera = points_camera[mask]\n",
    "\n",
    "    # Create intrinsic matrix\n",
    "    fx, fy, cx, cy = camera_intrinsics.params  # Assuming Pinhole model (fx, fy, cx, cy)\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    # Project points onto the image plane\n",
    "    projected_points = (K @ points_camera.T).T\n",
    "    projected_points = projected_points[:, :2] / projected_points[:, 2].reshape(-1, 1)\n",
    "\n",
    "\n",
    "    # Return only the points within the image boundaries\n",
    "    return projected_points.astype(int), mask\n",
    "\n",
    "def get_extrinsic_matrix(qvec, tvec):\n",
    "    \"\"\"\n",
    "    Create a 4x4 extrinsic matrix from quaternion and translation vector.\n",
    "    \n",
    "    Parameters:\n",
    "    - qvec: np.ndarray - Quaternion (w, x, y, z) representing rotation.\n",
    "    - tvec: np.ndarray - Translation vector (x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "    - extrinsic_matrix: np.ndarray - 4x4 extrinsic matrix.\n",
    "    \"\"\"\n",
    "    # Convert quaternion to rotation matrix\n",
    "    rotation_matrix = qvec2rotmat(qvec)\n",
    "    \n",
    "    # Create 4x4 extrinsic matrix\n",
    "    extrinsic_matrix = np.eye(4)\n",
    "    extrinsic_matrix[:3, :3] = rotation_matrix\n",
    "    extrinsic_matrix[:3, 3] = tvec\n",
    "    \n",
    "    return extrinsic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_point_cloud(point_cloud, colors, camera_intrinsics, extrinsics):\n",
    "    \"\"\"\n",
    "    Project a 3D point cloud onto a 2D image plane.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (np.ndarray): Nx3 array of 3D points.\n",
    "        camera_intrinsics (Camera): Camera object with intrinsic parameters.\n",
    "        extrinsics (np.ndarray): 4x4 matrix for camera extrinsics.\n",
    "\n",
    "    Returns:\n",
    "        projected_points (np.ndarray): Mx2 array of 2D projected points (filtered by visibility).\n",
    "        valid_mask (np.ndarray): Boolean mask indicating the visible points (length matches filtered points).\n",
    "    \"\"\"\n",
    "    if extrinsics.shape != (4, 4):\n",
    "        raise ValueError(\"Extrinsics must be a 4x4 matrix.\")\n",
    "\n",
    "    # Add a column of ones to the point cloud to make it homogeneous\n",
    "    points_homogeneous = np.hstack((point_cloud, np.ones((point_cloud.shape[0], 1))))\n",
    "\n",
    "    # Transform points to the camera coordinate system using extrinsics\n",
    "    points_camera = (extrinsics @ points_homogeneous.T).T\n",
    "    points_camera = points_camera[:, :3]  # Extract x, y, z coordinates\n",
    "\n",
    "    # Keep only points with positive Z (in front of the camera)\n",
    "    visibility_mask = points_camera[:, 2] > 0\n",
    "    points_camera = points_camera[visibility_mask]\n",
    "    filtered_colors = colors[visibility_mask]\n",
    "\n",
    "    # Project points onto the 2D image plane using the intrinsic matrix\n",
    "    fx, fy, cx, cy = camera_intrinsics.params\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "    \n",
    "    projected_points = (K @ points_camera.T).T\n",
    "    projected_points = projected_points[:, :2] / projected_points[:, 2].reshape(-1, 1)\n",
    "\n",
    "    # Return filtered projected points and the valid mask\n",
    "    return projected_points.astype(int), filtered_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_point_cloud_image(point_cloud, camera, extrinsics, image_path, image_size=None, point_color=(0, 255, 0), alpha=0.5, point_size=2):\n",
    "    \"\"\"\n",
    "    Render a composite image with the projected point cloud and a masked original image.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (np.ndarray): Nx3 array of 3D points.\n",
    "        camera (Camera): Camera object with intrinsics.\n",
    "        extrinsics (np.ndarray): 4x4 camera extrinsic matrix.\n",
    "        image_path (str): Path to the input background image.\n",
    "        output_path (str): Path to save the output composite image.\n",
    "        image_size (tuple): Size of the output image (height, width).\n",
    "        point_color (tuple): RGB color of the points to render.\n",
    "        alpha (float): Opacity of the overlay.\n",
    "        point_size (int): Size of the projected points.\n",
    "    \"\"\"\n",
    "    if image_size is None:\n",
    "        image_size = (camera.height, camera.width)\n",
    "    \n",
    "    # Project the 3D points onto the 2D image plane\n",
    "    projected_points = project_point_cloud(point_cloud, camera, extrinsics)\n",
    "\n",
    "    # Create the point cloud image\n",
    "    point_cloud_image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    for point in projected_points:\n",
    "        cv2.circle(point_cloud_image, tuple(point), point_size, point_color, -1)\n",
    "\n",
    "    # Load the actual image\n",
    "    actual_image = cv2.imread(image_path)\n",
    "    if actual_image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    if actual_image.shape[:2] != image_size:\n",
    "        actual_image = cv2.resize(actual_image, (image_size[1], image_size[0]))\n",
    "\n",
    "    # Overlay the point cloud on the actual image\n",
    "    overlay_image = cv2.addWeighted(point_cloud_image, alpha, actual_image, 1 - alpha, 0)\n",
    "    return overlay_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_point_cloud_interpolated(point_cloud, colors, camera, extrinsics, output_path, image_size=None, alpha=0.5, point_size=1):\n",
    "    \"\"\"\n",
    "    Render a composite image with the projected point cloud and a masked original image.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (np.ndarray): Nx3 array of 3D points.\n",
    "        camera (Camera): Camera object with intrinsics.\n",
    "        extrinsics (np.ndarray): 4x4 camera extrinsic matrix.\n",
    "        image_path (str): Path to the input background image.\n",
    "        output_path (str): Path to save the output composite image.\n",
    "        image_size (tuple): Size of the output image (height, width).\n",
    "        point_color (tuple): RGB color of the points to render.\n",
    "        alpha (float): Opacity of the overlay.\n",
    "        point_size (int): Size of the projected points.\n",
    "    \"\"\"\n",
    "    if image_size is None:\n",
    "        image_size = (camera.height, camera.width)\n",
    "    \n",
    "    # Initialize the depth buffer and output image\n",
    "    depth_buffer = np.full(image_size, np.inf)  # Depth buffer initialized to infinity\n",
    "    point_cloud_image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Project the 3D points onto the 2D image plane\n",
    "    projected_points, colors = project_point_cloud(point_cloud, colors, camera, extrinsics)\n",
    "\n",
    "    points_camera = (extrinsics @ np.hstack((point_cloud, np.ones((point_cloud.shape[0], 1)))).T).T\n",
    "\n",
    "    # Iterate through projected points and apply depth testing\n",
    "    for idx, (u, v) in enumerate(projected_points):\n",
    "        z = points_camera[idx, 2]  # Depth value\n",
    "        u, v = int(round(u)), int(round(v))\n",
    "\n",
    "        # Check if point is within image bounds\n",
    "        if 0 <= u < image_size[1] and 0 <= v < image_size[0]:\n",
    "            # Depth test: Render only if this point is closer\n",
    "            if z < depth_buffer[v, u]:\n",
    "                depth_buffer[v, u] = z  # Update depth buffer\n",
    "                color = colors[idx]\n",
    "                point_color = (int(color[2]), int(color[1]), int(color[0]))\n",
    "                cv2.circle(point_cloud_image, (u, v), point_size, point_color, -1)\n",
    "\n",
    "    # Save the final image\n",
    "    cv2.imwrite(output_path, point_cloud_image)\n",
    "    return point_cloud_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points_to_image(camera_id, cam_extrinsics, cam_intrinsics, object_name, points):\n",
    "    camera = cam_intrinsics[camera_id] if camera_id in cam_intrinsics else cam_intrinsics[list(cam_intrinsics.keys())[0]]\n",
    "    qvec = cam_extrinsics[camera_id].qvec\n",
    "    tvec = cam_extrinsics[camera_id].tvec\n",
    "    extrinsics = get_extrinsic_matrix(qvec, tvec)\n",
    "    name = cam_extrinsics[camera_id].name\n",
    "    image = render_point_cloud_image(points, camera, extrinsics, image_path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def slerp(q1, q2, t):\n",
    "    \"\"\"\n",
    "    Spherical Linear Interpolation between two quaternions.\n",
    "    \"\"\"\n",
    "    q1 = R.from_quat(q1)\n",
    "    q2 = R.from_quat(q2)\n",
    "    slerp_instance = Slerp([0, 1], R.from_quat([q1.as_quat(), q2.as_quat()]))\n",
    "    return slerp_instance([t])[0].as_quat()\n",
    "\n",
    "def interpolate_camera_poses(camera_ids, cam_extrinsics, num_samples=200, zoom_factor=1.0):\n",
    "    \"\"\"\n",
    "    Interpolates camera poses with an option to adjust the path for a zoomed-out effect.\n",
    "\n",
    "    Parameters:\n",
    "    - camera_ids: List of camera IDs for interpolation.\n",
    "    - cam_extrinsics: Dictionary containing camera extrinsics (qvec and tvec).\n",
    "    - num_samples: Number of interpolated poses to generate.\n",
    "    - zoom_factor: Multiplier for \"zooming out\" the camera path. Values >1 push cameras further out.\n",
    "\n",
    "    Returns:\n",
    "    - List of interpolated poses as tuples (qvec, tvec).\n",
    "    \"\"\"\n",
    "    poses = []\n",
    "    for i in range(len(camera_ids) - 1):\n",
    "        q1 = cam_extrinsics[camera_ids[i]].qvec\n",
    "        t1 = cam_extrinsics[camera_ids[i]].tvec\n",
    "        q2 = cam_extrinsics[camera_ids[i + 1]].qvec\n",
    "        t2 = cam_extrinsics[camera_ids[i + 1]].tvec\n",
    "\n",
    "        # Compute the direction vector for zoom adjustment\n",
    "        direction_vector = t2 - t1\n",
    "\n",
    "        for j in range(num_samples // (len(camera_ids) - 1)):\n",
    "            t = j / (num_samples // (len(camera_ids) - 1))\n",
    "            interpolated_q = slerp(q1, q2, t)\n",
    "            interpolated_t = (1 - t) * t1 + t * t2\n",
    "\n",
    "            # Apply zoom factor to the translation vector\n",
    "            center_t = (t1 + t2) / 2  # Find the midpoint for zoom adjustment\n",
    "            zoomed_t = interpolated_t + (interpolated_t - center_t) * (zoom_factor - 1)\n",
    "\n",
    "            poses.append((interpolated_q, zoomed_t))\n",
    "    return poses\n",
    "\n",
    "\n",
    "def render_interpolated_video(camera_ids, cam_extrinsics, cam_intrinsics, points, colors, num_samples=200, output_dir=\"output\", zoom_factor=1.0):\n",
    "    interpolated_poses = interpolate_camera_poses(camera_ids, cam_extrinsics, num_samples, zoom_factor)\n",
    "    image_size = (cam_intrinsics[1].height, cam_intrinsics[1].width)\n",
    "    for i, (qvec, tvec) in enumerate(tqdm(interpolated_poses, desc=\"Rendering Frames\", unit=\"frame\")):\n",
    "        extrinsics = get_extrinsic_matrix(qvec, tvec)\n",
    "        camera_id = 1  # Use the first camera's intrinsics\n",
    "        camera = cam_intrinsics[camera_id]\n",
    "        image_path = f\"{output_dir}/frame_{i:04d}.png\"\n",
    "        render_point_cloud_interpolated(points, colors, camera, extrinsics, image_path, image_size=image_size)\n",
    "    print(f\"Rendered {len(interpolated_poses)} frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 241367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering Frames: 100%|██████████| 200/200 [03:26<00:00,  1.03s/frame]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered 200 frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define camera positions and orientations\n",
    "camera_ids = [1, 280]\n",
    "camera_positions = np.array([\n",
    "    [0.747852111589277, -2.1887432598651739, 3.3341802907528604],  # Camera 1 position\n",
    "    [0.31344161331034526, -2.1952116629036906, 2.8254937930775985],  # Camera 2 position\n",
    "    [0.17202464003031009, -1.8970149533814831, 2.880851400336415],   # Camera 3 position\n",
    "    [4.63097, -2.10853, -6.58023]\n",
    "])\n",
    "\n",
    "camera_orientations = [\n",
    "    R.from_quat([-0.13577322541282349, -0.40936959454237748, -0.18740952320445933, 0.88253036034885812]),  # Camera 1\n",
    "    R.from_quat([-0.11390566885617641, -0.076043765232894661, -0.061089609451369535, 0.98869151103299691]),  # Camera 2\n",
    "    R.from_quat([-0.13913855551931867, 0.52118708493071131, 0.26265739115675008, 0.80000973727833791]),      # Camera 3\n",
    "    R.from_quat([-0.339762, 0.580685, -0.736785, 0.067198])\n",
    "]\n",
    "\n",
    "object_name = \"kitchen\"\n",
    "points, colors, normals = read_ply(f'data/points_{object_name}.ply')\n",
    "cam_extrinsics = read_extrinsics_text(f\"data/{object_name}/sparse/0/images.txt\")\n",
    "cam_intrinsics = read_intrinsics_text(f\"data/{object_name}/sparse/0/cameras.txt\")\n",
    "# Sample Usage\n",
    "render_interpolated_video(camera_ids, cam_extrinsics, cam_intrinsics, points, colors, num_samples=200, output_dir=f\"output/{object_name}/videoframes2\", zoom_factor=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
