{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from plyfile import PlyData\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ply(file_path):\n",
    "    plydata = PlyData.read(file_path)\n",
    "    x = plydata['vertex']['x']\n",
    "    y = plydata['vertex']['y']\n",
    "    z = plydata['vertex']['z']\n",
    "    if 'red' in plydata['vertex']:\n",
    "        r = plydata['vertex']['red']\n",
    "        g = plydata['vertex']['green']\n",
    "        b = plydata['vertex']['blue']\n",
    "        colors = np.array([r, g, b]).T\n",
    "    else:\n",
    "        colors = None\n",
    "    if 'nx' in plydata['vertex']:\n",
    "        nx = plydata['vertex']['nx']\n",
    "        ny = plydata['vertex']['ny']\n",
    "        nz = plydata['vertex']['nz']\n",
    "        normals = np.array([nx, ny, nz]).T\n",
    "    else:\n",
    "        normals = None\n",
    "    points = np.array([x, y, z]).T\n",
    "    print(f\"Number of points: {points.shape[0]}\")\n",
    "    return points, colors, normals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Original Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_point_cloud(points, colors=None):\n",
    "    fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scatter3d'}]])\n",
    "    fig.add_trace(go.Scatter3d(x=points[:, 0], y=points[:, 1], z=points[:, 2], mode='markers', marker=dict(size=1, color=colors)), row=1, col=1)\n",
    "    fig.update_layout(width=1000, height=1000)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(points, eps=0.5, min_samples=200):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(points)\n",
    "    return labels\n",
    "\n",
    "def get_peaks(density, min_peak_points, sigma, plot=False):\n",
    "    density = np.sort(density)\n",
    "    density = density[int(0.1 * len(density)):]\n",
    "    density_values, bin_edges = np.histogram(density, bins=100) \n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    smoothed_density = gaussian_filter1d(density_values, sigma=sigma)\n",
    "\n",
    "    peaks, _ = find_peaks(smoothed_density, height=min_peak_points)  # Adjust height to filter out small peaks\n",
    "\n",
    "    peak_boundaries = []\n",
    "    for peak in peaks:\n",
    "        start, end = peak, peak\n",
    "\n",
    "        while start > 0 and smoothed_density[start - 1] < smoothed_density[start]:\n",
    "            start -= 1\n",
    "        \n",
    "        while end < len(smoothed_density) - 1 and smoothed_density[end + 1] < smoothed_density[end]:\n",
    "            end += 1\n",
    "\n",
    "        peak_boundaries.append((start, end))\n",
    "\n",
    "    if plot:\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers,\n",
    "            y=density_values,\n",
    "            mode='lines',\n",
    "            name=\"Original Histogram\"\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers,\n",
    "            y=smoothed_density,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange'),\n",
    "            name=\"Smoothed Histogram\"\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers[peaks],\n",
    "            y=smoothed_density[peaks],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red', size=10, symbol='x'),\n",
    "            name=\"Detected Peaks\"\n",
    "        ))\n",
    "\n",
    "        for idx, (start, end) in enumerate(peak_boundaries):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[bin_centers[start], bin_centers[start]],\n",
    "                y=[0, max(density_values)],\n",
    "                mode='lines',\n",
    "                line=dict(color='green', dash='dash'),\n",
    "                showlegend=idx == 0,\n",
    "                name=\"Peak Start\" if idx == 0 else None\n",
    "            ))\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[bin_centers[end], bin_centers[end]],\n",
    "                y=[0, max(density_values)],\n",
    "                mode='lines',\n",
    "                line=dict(color='purple', dash='dash'),\n",
    "                showlegend=idx == 0,\n",
    "                name=\"Peak End\" if idx == 0 else None\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"Density Histogram with Peak Detection\",\n",
    "            xaxis_title=\"Density\",\n",
    "            yaxis_title=\"Number of Points\",\n",
    "            legend=dict(\n",
    "                x=1.0,\n",
    "                y=1.0,\n",
    "                xanchor='right',\n",
    "                yanchor='top',\n",
    "                bgcolor='rgba(255, 255, 255, 0.5)',\n",
    "                bordercolor='Black',\n",
    "                borderwidth=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    return peak_boundaries, bin_centers\n",
    "\n",
    "\n",
    "def monte_carlo_kde(points, bandwidth: float, sample_size: int = 500, num_samples: int = 10):\n",
    "    densities = []\n",
    "    for _ in range(num_samples):\n",
    "        sample_indices = np.random.choice(len(points), sample_size, replace=False)\n",
    "        sample_points = points[sample_indices]\n",
    "\n",
    "        kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "        kde.fit(sample_points)\n",
    "        \n",
    "        log_density = kde.score_samples(points)\n",
    "        densities.append(np.exp(log_density))\n",
    "\n",
    "    # Aggregate results (e.g., average density estimates)\n",
    "    density = np.mean(densities, axis=0)\n",
    "    return density\n",
    "\n",
    "def get_densest_cluster(points, min_peak_points, kde_samples=1000, sigma=2, colors=None, plot=False):\n",
    "    # density = monte_carlo_kde(points, bandwidth=1, sample_size=max(len(points) // 100, 3000))  \n",
    "    density = monte_carlo_kde(points, bandwidth=1, sample_size=kde_samples)  \n",
    "    peak_boundaries, bin_centers = get_peaks(density, min_peak_points, sigma=sigma, plot=True)\n",
    "    first_peak_end_index = peak_boundaries[0][0]\n",
    "    first_peak_end = bin_centers[first_peak_end_index]\n",
    "    print(f\"First peak ends at density {first_peak_end}\")\n",
    "    points = points[density > first_peak_end]\n",
    "    density = density[density > first_peak_end]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if plot:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "                # color uses r, g, and b\n",
    "                color=density,\n",
    "                colorscale='Viridis',\n",
    "                colorbar=dict(title='Density'),\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            scene=dict(\n",
    "                xaxis_title='X',\n",
    "                yaxis_title='Y',\n",
    "                zaxis_title='Z'\n",
    "            ),\n",
    "            title=\"3D Point Cloud with Density Color-Coding\"\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    return points, density\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_floor_plane(points, distance_threshold=0.02, min_floor_points=100):\n",
    "    \"\"\"Find the floor plane in a point cloud.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    plane_model, inliers = pcd.segment_plane(\n",
    "        distance_threshold=distance_threshold,\n",
    "        ransac_n=3,\n",
    "        num_iterations=1000\n",
    "    )\n",
    "    \n",
    "\n",
    "    inlier_mask = np.zeros(len(points), dtype=bool)\n",
    "    inlier_mask[inliers] = True\n",
    "    \n",
    "    print(f\"Number of inlier indices: {len(inliers)}\")\n",
    "    print(f\"Number of True values in inliers: {np.sum(inliers)}\")\n",
    "    \n",
    "    floor_points = points[inlier_mask]\n",
    "    non_floor_points = points[~inlier_mask]\n",
    "    \n",
    "    print(f\"Number of floor points: {len(floor_points)}\")\n",
    "    print(f\"Number of non-floor points: {len(non_floor_points)}\")\n",
    "    \n",
    "    if len(floor_points) < min_floor_points:\n",
    "        print(f\"Warning: Found only {len(floor_points)} floor points. Might be unreliable.\")\n",
    "    \n",
    "    return floor_points, non_floor_points, plane_model\n",
    "\n",
    "\n",
    "def find_optimal_threshold(points, \n",
    "                           initial_threshold=0.01, \n",
    "                           max_threshold=0.2, \n",
    "                           iterations=50):\n",
    "    \"\"\"\n",
    "    Automatically find optimal distance threshold for floor detection without predefined floor ratio bounds.\n",
    "    The function iteratively adjusts the threshold and monitors the change in floor_ratio to determine when to stop.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : np.ndarray\n",
    "        Input point cloud as a NumPy array of shape (N, 3).\n",
    "    initial_threshold : float, default=0.02\n",
    "        Starting distance threshold value.\n",
    "    max_threshold : float, default=0.1\n",
    "        Maximum allowed threshold.\n",
    "    iterations : int, default=10\n",
    "        Maximum number of iterations for searching the optimal threshold.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    best_threshold : float\n",
    "        The optimal distance threshold found.\n",
    "    best_ratio : float\n",
    "        The ratio of floor points corresponding to the optimal threshold.\n",
    "    stats : dict\n",
    "        Dictionary containing statistics about the threshold search process.\n",
    "    \"\"\"\n",
    "    total_points = len(points)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    # Calculate point cloud statistics\n",
    "    distances = np.asarray(pcd.compute_nearest_neighbor_distance())\n",
    "    median_distance = np.median(distances)\n",
    "    \n",
    "    # Initialize threshold search\n",
    "    threshold = initial_threshold\n",
    "    best_threshold = threshold\n",
    "    best_ratio = 0\n",
    "    \n",
    "    stats = {\n",
    "        'iterations': [],\n",
    "        'thresholds': [],\n",
    "        'floor_ratios': [],\n",
    "        'improvements': [],\n",
    "        'median_distance': median_distance\n",
    "    }\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        # Segment plane with current threshold\n",
    "        plane_model, inliers = pcd.segment_plane(\n",
    "            distance_threshold=threshold,\n",
    "            ransac_n=3,\n",
    "            num_iterations=1000\n",
    "        )\n",
    "        \n",
    "        floor_ratio = len(inliers) / total_points\n",
    "        \n",
    "        # Store statistics\n",
    "        stats['iterations'].append(iteration)\n",
    "        stats['thresholds'].append(threshold)\n",
    "        stats['floor_ratios'].append(floor_ratio)        \n",
    "\n",
    "        if threshold >= max_threshold:\n",
    "            print(f\"Stopping search: Reached maximum threshold {max_threshold}\")\n",
    "            break\n",
    "\n",
    "        threshold += (max_threshold - initial_threshold) / iterations\n",
    "        threshold = min(threshold, max_threshold)\n",
    "    \n",
    "    smoothed_ratios = gaussian_filter1d(stats['floor_ratios'], sigma=3)\n",
    "    second_derivative = np.gradient(np.gradient(smoothed_ratios))\n",
    "    # best threshold is the one with the lowest second derivative\n",
    "    best_threshold = stats['thresholds'][np.argmin(second_derivative)]\n",
    "    best_ratio = stats['floor_ratios'][np.argmin(second_derivative)]\n",
    "    \n",
    "\n",
    "    # Collect final statistics\n",
    "    stats['optimal_threshold'] = best_threshold\n",
    "    stats['final_floor_ratio'] = best_ratio\n",
    "    stats['median_point_distance'] = median_distance\n",
    "    \n",
    "    return best_threshold, best_ratio, stats\n",
    "\n",
    "def find_floor_plane_auto(points, min_floor_points=100, visualize_threshold_search=False):\n",
    "    \"\"\"\n",
    "    Enhanced floor detection with automatic threshold selection.\n",
    "    \"\"\"\n",
    "    optimal_threshold, floor_ratio, stats = find_optimal_threshold(points)\n",
    "    \n",
    "    if visualize_threshold_search:\n",
    "        # Create visualization of threshold search\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Plot threshold evolution\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=stats['thresholds'],\n",
    "            name='Threshold',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='red'),\n",
    "        ))\n",
    "        \n",
    "        # Plot floor ratio evolution\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=stats['floor_ratios'],\n",
    "            name='Floor Ratio',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='cyan'),\n",
    "            yaxis='y2'\n",
    "        ))\n",
    "\n",
    "        smoothed_floor_ratio = gaussian_filter1d(stats['floor_ratios'], sigma=3)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=smoothed_floor_ratio,\n",
    "            name='Smoothed Floor Ratio',\n",
    "            mode='lines',\n",
    "            line=dict(color='blue'),\n",
    "            yaxis='y2'\n",
    "        ))\n",
    "\n",
    "\n",
    "        # plot 2nd derivative of floor ratio\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=np.gradient(np.gradient(smoothed_floor_ratio)),\n",
    "            name='2nd Derivative of Floor Ratio',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='blue'),\n",
    "        ))\n",
    "        \n",
    "        # Plot floor ratio evolution\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=stats['improvements'],\n",
    "            name='Improvements',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='blue'),\n",
    "            yaxis='y2'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Threshold Search Evolution',\n",
    "            xaxis_title='Iteration',\n",
    "            yaxis_title='Threshold',\n",
    "            yaxis2=dict(\n",
    "                title='Floor Ratio',\n",
    "                overlaying='y',\n",
    "                side='right'\n",
    "            )\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    print(f\"Found optimal threshold: {optimal_threshold:.4f}\")\n",
    "    print(f\"Floor ratio: {floor_ratio:.2%}\")\n",
    "    print(f\"Median point distance: {stats['median_point_distance']:.4f}\")\n",
    "    \n",
    "    return find_floor_plane(points, distance_threshold=optimal_threshold, \n",
    "                          min_floor_points=min_floor_points)\n",
    "\n",
    "\n",
    "def determine_model_orientation(points, plane_model):\n",
    "    \"\"\"Determine if the model is upside down relative to the floor plane.\"\"\"\n",
    "    a, b, c, d = plane_model\n",
    "    normal_vector = np.array([a, b, c])\n",
    "    \n",
    "    signed_distances = (points @ normal_vector + d)\n",
    "    \n",
    "    points_above = points[signed_distances > 0]\n",
    "    points_below = points[signed_distances < 0]\n",
    "    total_points = len(points)\n",
    "    \n",
    "    is_upside_down = (len(points_below) / total_points) > 0.2\n",
    "    \n",
    "    orientation_info = {\n",
    "        \"points_above_floor\": points_above,\n",
    "        \"points_below_floor\": points_below,\n",
    "        \"ratio_above\": points_above / total_points,\n",
    "        \"ratio_below\": points_below / total_points,\n",
    "        \"is_upside_down\": is_upside_down,\n",
    "        \"floor_normal\": normal_vector\n",
    "    }\n",
    "    \n",
    "    return orientation_info\n",
    "\n",
    "def align_to_xy_plane(points, plane_model, orientation_info):\n",
    "    \"\"\"Align the point cloud so the floor is parallel to the XY plane and positioned at z=0.\"\"\"\n",
    "    # Extract plane parameters\n",
    "    a, b, c, d = plane_model\n",
    "    floor_normal = np.array([a, b, c])\n",
    "    \n",
    "    # If the model is upside down, flip the normal\n",
    "    if orientation_info[\"is_upside_down\"]:\n",
    "        floor_normal = -floor_normal\n",
    "    \n",
    "    # Define the target normal (Z-axis)\n",
    "    z_axis = np.array([0, 0, 1])\n",
    "    \n",
    "    # Calculate rotation required to align floor_normal with Z-axis\n",
    "    rotation_axis = np.cross(floor_normal, z_axis)\n",
    "    norm_rotation_axis = np.linalg.norm(rotation_axis)\n",
    "    \n",
    "    if norm_rotation_axis < 1e-6:\n",
    "        # The normals are already aligned or opposite\n",
    "        if np.dot(floor_normal, z_axis) < 0:\n",
    "            rotation_matrix = -np.eye(3)\n",
    "        else:\n",
    "            rotation_matrix = np.eye(3)\n",
    "    else:\n",
    "        rotation_axis /= norm_rotation_axis\n",
    "        rotation_angle = np.arccos(np.clip(np.dot(floor_normal, z_axis), -1.0, 1.0))\n",
    "        rotation = Rotation.from_rotvec(rotation_angle * rotation_axis)\n",
    "        rotation_matrix = rotation.as_matrix()\n",
    "    \n",
    "    # Rotate all points\n",
    "    rotated_points = (rotation_matrix @ points.T).T\n",
    "    \n",
    "    # Find a point on the original plane\n",
    "    plane_norm_sq = a**2 + b**2 + c**2\n",
    "    if plane_norm_sq == 0:\n",
    "        raise ValueError(\"Invalid plane model with zero normal vector.\")\n",
    "    p0 = np.array([-a * d / plane_norm_sq,\n",
    "                   -b * d / plane_norm_sq,\n",
    "                   -c * d / plane_norm_sq])\n",
    "    \n",
    "    # Rotate the point on the plane\n",
    "    p0_rotated = rotation_matrix @ p0\n",
    "    \n",
    "    # Calculate translation to bring the rotated plane to z=0\n",
    "    translation_z = -p0_rotated[2]\n",
    "    translation = np.array([0, 0, translation_z])\n",
    "    \n",
    "    # Apply translation\n",
    "    aligned_points = rotated_points + translation\n",
    "    \n",
    "    return aligned_points, rotation_matrix, translation\n",
    "\n",
    "def remove_points_below_floor(points, plane_model):\n",
    "    \"\"\"Remove points below the floor.\"\"\"\n",
    "    above_floor_mask = points[:, 2] >= 0\n",
    "    return points[above_floor_mask]\n",
    "\n",
    "def denoise_point_cloud(points, neighbors=20, std_ratio=0.1):\n",
    "    \"\"\"Denoise the point cloud using statistical outlier removal.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    cl, ind = pcd.remove_statistical_outlier(nb_neighbors=neighbors, std_ratio=std_ratio)\n",
    "    return np.asarray(pcd.points)[ind]\n",
    "\n",
    "def process_point_cloud(points, min_floor_points=500, distance_threshold=None):\n",
    "    \"\"\"Complete pipeline to process the point cloud.\"\"\"\n",
    "    result = {}\n",
    "    # 1. Find floor\n",
    "    \n",
    "    if distance_threshold is None:\n",
    "        floor_points, non_floor_points, plane_model = find_floor_plane_auto(\n",
    "            points, \n",
    "            min_floor_points=min_floor_points,\n",
    "            visualize_threshold_search=True\n",
    "        )\n",
    "    else:\n",
    "        # floor_points, non_floor_points, plane_model = find_largest_surface_floor(points, distance_threshold=distance_threshold, \n",
    "        #                   min_floor_points=min_floor_points)\n",
    "        floor_points, non_floor_points, plane_model = find_floor_plane(points, distance_threshold=distance_threshold, \n",
    "                          min_floor_points=min_floor_points)\n",
    "    result['floor_points'] = floor_points\n",
    "    result['non_floor_points'] = non_floor_points\n",
    "    result['plane_model'] = plane_model\n",
    "    \n",
    "    # 2. Determine model orientation\n",
    "    orientation_info = determine_model_orientation(\n",
    "        non_floor_points, \n",
    "        plane_model\n",
    "    )\n",
    "    \n",
    "    # 3. Align to XY plane\n",
    "    aligned_points, rotation_matrix, translation = align_to_xy_plane(\n",
    "        non_floor_points, \n",
    "        plane_model, \n",
    "        orientation_info\n",
    "    )\n",
    "    result['aligned_points'] = aligned_points\n",
    "    result['orientation_info'] = orientation_info\n",
    "    result['transformation'] = {\n",
    "        'rotation': rotation_matrix,\n",
    "        'translation': translation\n",
    "    }\n",
    "\n",
    "    final_points = orientation_info[\"points_below_floor\"] if orientation_info[\"is_upside_down\"] else orientation_info[\"points_above_floor\"]\n",
    "\n",
    "    \n",
    "    # 4. Remove points below floor\n",
    "    # final_points = remove_points_below_floor(final_points, plane_model)\n",
    "    result['final_points'] = final_points\n",
    "\n",
    "    # 5. Denoise point cloud\n",
    "    denoised_points = denoise_point_cloud(final_points)\n",
    "    result['denoised_points'] = denoised_points\n",
    "\n",
    "    # 6. Denoise point cloud DBSCAN\n",
    "    dbscan_labels = dbscan(final_points, eps=0.9)\n",
    "    result['dbscan_labels'] = dbscan_labels\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Floor Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points_3d(points, color='blue', size=2, opacity=0.6):\n",
    "    \"\"\"Create a basic 3D scatter plot for points.\"\"\"\n",
    "    return go.Scatter3d(\n",
    "        x=points[:, 0], y=points[:, 1], z=points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=size,\n",
    "            color=color,\n",
    "            opacity=opacity\n",
    "        ),\n",
    "        name=f'Points ({len(points)} pts)'\n",
    "    )\n",
    "\n",
    "def plot_plane(plane_model, points, grid_size=20):\n",
    "    \"\"\"Create a surface plot for a plane within the points bounds.\"\"\"\n",
    "    a, b, c, d = plane_model\n",
    "    \n",
    "    # Get bounds from points\n",
    "    x_min, x_max = points[:, 0].min(), points[:, 0].max()\n",
    "    y_min, y_max = points[:, 1].min(), points[:, 1].max()\n",
    "    \n",
    "    # Create grid\n",
    "    x = np.linspace(x_min, x_max, grid_size)\n",
    "    y = np.linspace(y_min, y_max, grid_size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate Z values for the plane\n",
    "    if abs(c) > 1e-6:  # Ensure c is not close to zero\n",
    "        Z = (-a * X - b * Y - d) / c\n",
    "        Z = np.clip(Z, -3, 3)  # Limit Z values for plotting\n",
    "    else:\n",
    "        Z = np.zeros_like(X)  # Default to zero plane if c is very small\n",
    "\n",
    "    \n",
    "    return go.Surface(\n",
    "        x=X, y=Y, z=Z,\n",
    "        opacity=0.3,\n",
    "        showscale=False,\n",
    "        name='Floor plane'\n",
    "    )\n",
    "\n",
    "def visualize_floor_detection(points, floor_points, non_floor_points, plane_model):\n",
    "    \"\"\"Visualize the floor detection step.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add original points with low opacity\n",
    "    # fig.add_trace(plot_points_3d(points, color='gray', opacity=0.2))\n",
    "    \n",
    "    # Add floor points\n",
    "    fig.add_trace(plot_points_3d(floor_points, color='green', opacity=0.8))\n",
    "    \n",
    "    # Add non-floor points\n",
    "    fig.add_trace(plot_points_3d(non_floor_points, color='red', opacity=0.8))\n",
    "    \n",
    "    # Add floor plane\n",
    "    fig.add_trace(plot_plane(plane_model, points))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Floor Detection Results',\n",
    "        scene=dict(\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_orientation(points, plane_model, orientation_info):\n",
    "    \"\"\"Visualize the model orientation relative to the floor.\"\"\"\n",
    "    # Split points based on their position relative to the floor\n",
    "    a, b, c, d = plane_model\n",
    "    signed_distances = (points @ np.array([a, b, c]) + d)\n",
    "    \n",
    "    points_above = points[signed_distances > 0]\n",
    "    points_below = points[signed_distances < 0]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add points above floor\n",
    "    if len(points_above) > 0:\n",
    "        fig.add_trace(plot_points_3d(points_above, color='blue', opacity=0.8))\n",
    "    \n",
    "    # Add points below floor\n",
    "    if len(points_below) > 0:\n",
    "        fig.add_trace(plot_points_3d(points_below, color='red', opacity=0.8))\n",
    "    \n",
    "    # Add floor plane\n",
    "    fig.add_trace(plot_plane(plane_model, points))\n",
    "    \n",
    "    # Add floor normal vector at center of points\n",
    "    center = points.mean(axis=0)\n",
    "    normal = orientation_info['floor_normal'] * (points.max() - points.min()).mean() * 0.2\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[center[0], center[0] + normal[0]],\n",
    "        y=[center[1], center[1] + normal[1]],\n",
    "        z=[center[2], center[2] + normal[2]],\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='black', width=5),\n",
    "        name='Floor normal'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Model Orientation (Upside down: {orientation_info['is_upside_down']})\",\n",
    "        scene=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_alignment(original_points, aligned_points):\n",
    "    \"\"\"Visualize the alignment transformation.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
    "        subplot_titles=('Original Points', 'Aligned Points')\n",
    "    )\n",
    "    \n",
    "    # Original points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(original_points, color='blue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Aligned points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(aligned_points, color='green'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Point Cloud Alignment Results',\n",
    "        scene=dict(aspectmode='data'),\n",
    "        scene2=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_final_result(original_points, final_points):\n",
    "    \"\"\"Visualize the original vs final processed point cloud.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
    "        subplot_titles=('Original Point Cloud', 'Processed Point Cloud')\n",
    "    )\n",
    "    \n",
    "    # Original points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(original_points, color='blue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Final points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(final_points, color='green'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Final Processing Results',\n",
    "        scene=dict(aspectmode='data'),\n",
    "        scene2=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_complete_pipeline(result_dict):\n",
    "    \"\"\"Visualize all steps of the pipeline in a single figure.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        specs=[[{'type': 'scene'}, {'type': 'scene'}],\n",
    "               [{'type': 'scene'}, {'type': 'scene'}],\n",
    "               [{'type': 'scene'}, {'type': 'scene'}]],\n",
    "        subplot_titles=(\n",
    "            'Floor Detection',\n",
    "            'Orientation Analysis',\n",
    "            'Alignment Result',\n",
    "            'Final Result',\n",
    "            'Denoised Result Statistical Outlier',\n",
    "            'Denoised Result DBSCAN'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 1. Floor Detection\n",
    "    floor_trace = plot_points_3d(result_dict['floor_points'], color='green')\n",
    "    fig.add_trace(floor_trace, row=1, col=1)\n",
    "    \n",
    "    # 2. Orientation\n",
    "    # above_below_trace = plot_points_3d(result_dict['aligned_points'], color='blue')\n",
    "    # fig.add_trace(above_below_trace, row=1, col=2)\n",
    "    \n",
    "    # 3. Alignment\n",
    "    aligned_trace = plot_points_3d(result_dict['aligned_points'], color='orange')\n",
    "    fig.add_trace(aligned_trace, row=2, col=1)\n",
    "    \n",
    "    # 4. Final Result\n",
    "    final_trace = plot_points_3d(result_dict['final_points'], color='red')\n",
    "    fig.add_trace(final_trace, row=2, col=2)\n",
    "\n",
    "    # 5. Denoised Result Statistical Outlier\n",
    "    denoised_trace = plot_points_3d(result_dict['denoised_points'], color='purple')\n",
    "    fig.add_trace(denoised_trace, row=3, col=1)\n",
    "\n",
    "    # 6. Denoised Result DBSCAN\n",
    "    # INSERT CODE HERE\n",
    "    dbscan_labels = result_dict[\"dbscan_labels\"]\n",
    "    unique_labels = np.unique(dbscan_labels)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        color = 'gray' if label == -1 else f\"rgba({np.random.randint(0,255)},{np.random.randint(0,255)},{np.random.randint(0,255)},0.6)\"\n",
    "        label_points = result_dict['final_points'][dbscan_labels == label]\n",
    "        fig.add_trace(\n",
    "            plot_points_3d(label_points, color=color),\n",
    "            row=3, col=2\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        title='Complete Pipeline Visualization',\n",
    "        height=1000,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (C) 2023, Inria\n",
    "# GRAPHDECO research group, https://team.inria.fr/graphdeco\n",
    "# All rights reserved.\n",
    "#\n",
    "# This software is free for non-commercial, research and evaluation use \n",
    "# under the terms of the LICENSE.md file.\n",
    "#\n",
    "# For inquiries contact  george.drettakis@inria.fr\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import struct\n",
    "\n",
    "CameraModel = collections.namedtuple(\n",
    "    \"CameraModel\", [\"model_id\", \"model_name\", \"num_params\"])\n",
    "Camera = collections.namedtuple(\n",
    "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"])\n",
    "BaseImage = collections.namedtuple(\n",
    "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
    "Point3D = collections.namedtuple(\n",
    "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"])\n",
    "CAMERA_MODELS = {\n",
    "    CameraModel(model_id=0, model_name=\"SIMPLE_PINHOLE\", num_params=3),\n",
    "    CameraModel(model_id=1, model_name=\"PINHOLE\", num_params=4),\n",
    "    CameraModel(model_id=2, model_name=\"SIMPLE_RADIAL\", num_params=4),\n",
    "    CameraModel(model_id=3, model_name=\"RADIAL\", num_params=5),\n",
    "    CameraModel(model_id=4, model_name=\"OPENCV\", num_params=8),\n",
    "    CameraModel(model_id=5, model_name=\"OPENCV_FISHEYE\", num_params=8),\n",
    "    CameraModel(model_id=6, model_name=\"FULL_OPENCV\", num_params=12),\n",
    "    CameraModel(model_id=7, model_name=\"FOV\", num_params=5),\n",
    "    CameraModel(model_id=8, model_name=\"SIMPLE_RADIAL_FISHEYE\", num_params=4),\n",
    "    CameraModel(model_id=9, model_name=\"RADIAL_FISHEYE\", num_params=5),\n",
    "    CameraModel(model_id=10, model_name=\"THIN_PRISM_FISHEYE\", num_params=12)\n",
    "}\n",
    "CAMERA_MODEL_IDS = dict([(camera_model.model_id, camera_model)\n",
    "                         for camera_model in CAMERA_MODELS])\n",
    "CAMERA_MODEL_NAMES = dict([(camera_model.model_name, camera_model)\n",
    "                           for camera_model in CAMERA_MODELS])\n",
    "\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "def rotmat2qvec(R):\n",
    "    Rxx, Ryx, Rzx, Rxy, Ryy, Rzy, Rxz, Ryz, Rzz = R.flat\n",
    "    K = np.array([\n",
    "        [Rxx - Ryy - Rzz, 0, 0, 0],\n",
    "        [Ryx + Rxy, Ryy - Rxx - Rzz, 0, 0],\n",
    "        [Rzx + Rxz, Rzy + Ryz, Rzz - Rxx - Ryy, 0],\n",
    "        [Ryz - Rzy, Rzx - Rxz, Rxy - Ryx, Rxx + Ryy + Rzz]]) / 3.0\n",
    "    eigvals, eigvecs = np.linalg.eigh(K)\n",
    "    qvec = eigvecs[[3, 0, 1, 2], np.argmax(eigvals)]\n",
    "    if qvec[0] < 0:\n",
    "        qvec *= -1\n",
    "    return qvec\n",
    "\n",
    "class Image(BaseImage):\n",
    "    def qvec2rotmat(self):\n",
    "        return qvec2rotmat(self.qvec)\n",
    "\n",
    "def read_next_bytes(fid, num_bytes, format_char_sequence, endian_character=\"<\"):\n",
    "    \"\"\"Read and unpack the next bytes from a binary file.\n",
    "    :param fid:\n",
    "    :param num_bytes: Sum of combination of {2, 4, 8}, e.g. 2, 6, 16, 30, etc.\n",
    "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
    "    :param endian_character: Any of {@, =, <, >, !}\n",
    "    :return: Tuple of read and unpacked values.\n",
    "    \"\"\"\n",
    "    data = fid.read(num_bytes)\n",
    "    return struct.unpack(endian_character + format_char_sequence, data)\n",
    "\n",
    "def read_points3D_text(path):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DText(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DText(const std::string& path)\n",
    "    \"\"\"\n",
    "    xyzs = None\n",
    "    rgbs = None\n",
    "    errors = None\n",
    "    num_points = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                num_points += 1\n",
    "\n",
    "\n",
    "    xyzs = np.empty((num_points, 3))\n",
    "    rgbs = np.empty((num_points, 3))\n",
    "    errors = np.empty((num_points, 1))\n",
    "    count = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
    "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
    "                error = np.array(float(elems[7]))\n",
    "                xyzs[count] = xyz\n",
    "                rgbs[count] = rgb\n",
    "                errors[count] = error\n",
    "                count += 1\n",
    "\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_points3D_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DBinary(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_points = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "\n",
    "        xyzs = np.empty((num_points, 3))\n",
    "        rgbs = np.empty((num_points, 3))\n",
    "        errors = np.empty((num_points, 1))\n",
    "\n",
    "        for p_id in range(num_points):\n",
    "            binary_point_line_properties = read_next_bytes(\n",
    "                fid, num_bytes=43, format_char_sequence=\"QdddBBBd\")\n",
    "            xyz = np.array(binary_point_line_properties[1:4])\n",
    "            rgb = np.array(binary_point_line_properties[4:7])\n",
    "            error = np.array(binary_point_line_properties[7])\n",
    "            track_length = read_next_bytes(\n",
    "                fid, num_bytes=8, format_char_sequence=\"Q\")[0]\n",
    "            track_elems = read_next_bytes(\n",
    "                fid, num_bytes=8*track_length,\n",
    "                format_char_sequence=\"ii\"*track_length)\n",
    "            xyzs[p_id] = xyz\n",
    "            rgbs[p_id] = rgb\n",
    "            errors[p_id] = error\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_intrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                camera_id = int(elems[0])\n",
    "                model = elems[1]\n",
    "                assert model == \"PINHOLE\", \"While the loader support other types, the rest of the code assumes PINHOLE\"\n",
    "                width = int(elems[2])\n",
    "                height = int(elems[3])\n",
    "                params = np.array(tuple(map(float, elems[4:])))\n",
    "                cameras[camera_id] = Camera(id=camera_id, model=model,\n",
    "                                            width=width, height=height,\n",
    "                                            params=params)\n",
    "    return cameras\n",
    "\n",
    "def read_extrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadImagesBinary(const std::string& path)\n",
    "        void Reconstruction::WriteImagesBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_reg_images = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_reg_images):\n",
    "            binary_image_properties = read_next_bytes(\n",
    "                fid, num_bytes=64, format_char_sequence=\"idddddddi\")\n",
    "            image_id = binary_image_properties[0]\n",
    "            qvec = np.array(binary_image_properties[1:5])\n",
    "            tvec = np.array(binary_image_properties[5:8])\n",
    "            camera_id = binary_image_properties[8]\n",
    "            image_name = \"\"\n",
    "            current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            while current_char != b\"\\x00\":   # look for the ASCII 0 entry\n",
    "                image_name += current_char.decode(\"utf-8\")\n",
    "                current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            num_points2D = read_next_bytes(fid, num_bytes=8,\n",
    "                                           format_char_sequence=\"Q\")[0]\n",
    "            x_y_id_s = read_next_bytes(fid, num_bytes=24*num_points2D,\n",
    "                                       format_char_sequence=\"ddq\"*num_points2D)\n",
    "            xys = np.column_stack([tuple(map(float, x_y_id_s[0::3])),\n",
    "                                   tuple(map(float, x_y_id_s[1::3]))])\n",
    "            point3D_ids = np.array(tuple(map(int, x_y_id_s[2::3])))\n",
    "            images[image_id] = Image(\n",
    "                id=image_id, qvec=qvec, tvec=tvec,\n",
    "                camera_id=camera_id, name=image_name,\n",
    "                xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_intrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::WriteCamerasBinary(const std::string& path)\n",
    "        void Reconstruction::ReadCamerasBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_cameras = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_cameras):\n",
    "            camera_properties = read_next_bytes(\n",
    "                fid, num_bytes=24, format_char_sequence=\"iiQQ\")\n",
    "            camera_id = camera_properties[0]\n",
    "            model_id = camera_properties[1]\n",
    "            model_name = CAMERA_MODEL_IDS[camera_properties[1]].model_name\n",
    "            width = camera_properties[2]\n",
    "            height = camera_properties[3]\n",
    "            num_params = CAMERA_MODEL_IDS[model_id].num_params\n",
    "            params = read_next_bytes(fid, num_bytes=8*num_params,\n",
    "                                     format_char_sequence=\"d\"*num_params)\n",
    "            cameras[camera_id] = Camera(id=camera_id,\n",
    "                                        model=model_name,\n",
    "                                        width=width,\n",
    "                                        height=height,\n",
    "                                        params=np.array(params))\n",
    "        assert len(cameras) == num_cameras\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def read_extrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
    "                                       tuple(map(float, elems[1::3]))])\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id, qvec=qvec, tvec=tvec,\n",
    "                    camera_id=camera_id, name=image_name,\n",
    "                    xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_colmap_bin_array(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_dense.py\n",
    "\n",
    "    :param path: path to the colmap binary file.\n",
    "    :return: nd array with the floating point values in the value\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as fid:\n",
    "        width, height, channels = np.genfromtxt(fid, delimiter=\"&\", max_rows=1,\n",
    "                                                usecols=(0, 1, 2), dtype=int)\n",
    "        fid.seek(0)\n",
    "        num_delimiter = 0\n",
    "        byte = fid.read(1)\n",
    "        while True:\n",
    "            if byte == b\"&\":\n",
    "                num_delimiter += 1\n",
    "                if num_delimiter >= 3:\n",
    "                    break\n",
    "            byte = fid.read(1)\n",
    "        array = np.fromfile(fid, np.float32)\n",
    "    array = array.reshape((width, height, channels), order=\"F\")\n",
    "    return np.transpose(array, (1, 0, 2)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Floor Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_floor_separation(points, min_floor_points=500, distance_threshold=None):\n",
    "    result = process_point_cloud(points, min_floor_points, distance_threshold)\n",
    "    print(f\"Floor points: {len(result['floor_points'])}, Non-floor points: {len(result['non_floor_points'])}\")\n",
    "    # Visualize individual steps\n",
    "    fig_floor = visualize_floor_detection(\n",
    "        points, \n",
    "        result['floor_points'], \n",
    "        result['non_floor_points'], \n",
    "        result['plane_model']\n",
    "    )\n",
    "    fig_floor.show()\n",
    "\n",
    "    fig_orientation = visualize_orientation(\n",
    "        points, \n",
    "        result['plane_model'], \n",
    "        result['orientation_info']\n",
    "    )\n",
    "    fig_orientation.show()\n",
    "\n",
    "    fig_alignment = visualize_alignment(\n",
    "        points, \n",
    "        result['aligned_points']\n",
    "    )\n",
    "    fig_alignment.show()\n",
    "\n",
    "    fig_final = visualize_final_result(\n",
    "        points, \n",
    "        result['final_points']\n",
    "    )\n",
    "    fig_final.show()\n",
    "\n",
    "    # # Or visualize everything at once\n",
    "    fig_complete = visualize_complete_pipeline(result)\n",
    "    fig_complete.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(points_3d, camera_intrinsics, extrinsics):\n",
    "    \"\"\"\n",
    "    Project 3D points onto a 2D image plane using camera intrinsics and extrinsics.\n",
    "    \n",
    "    Parameters:\n",
    "    - points_3d: np.ndarray - Array of 3D points (N, 3).\n",
    "    - camera_intrinsics: Camera - The camera intrinsics (e.g., focal length, principal point).\n",
    "    - extrinsics: np.ndarray - 4x4 extrinsic matrix (rotation and translation).\n",
    "\n",
    "    Returns:\n",
    "    - projected_points: np.ndarray - 2D projected points in image space.\n",
    "    - mask: np.ndarray - Boolean array indicating which points are in front of the camera.\n",
    "    \"\"\"\n",
    "    # Convert points to homogeneous coordinates\n",
    "    points_homogeneous = np.hstack((points_3d, np.ones((points_3d.shape[0], 1))))\n",
    "    \n",
    "    # Transform 3D points to the camera coordinate system\n",
    "    points_camera = (extrinsics @ points_homogeneous.T).T\n",
    "    points_camera = points_camera[:, :3]\n",
    "\n",
    "    # Filter points in front of the camera\n",
    "    mask = points_camera[:, 2] > 0  # Keep points with positive Z\n",
    "    points_camera = points_camera[mask]\n",
    "\n",
    "    # Create intrinsic matrix\n",
    "    fx, fy, cx, cy = camera_intrinsics.params  # Assuming Pinhole model (fx, fy, cx, cy)\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    # Project points onto the image plane\n",
    "    projected_points = (K @ points_camera.T).T\n",
    "    projected_points = projected_points[:, :2] / projected_points[:, 2].reshape(-1, 1)\n",
    "\n",
    "\n",
    "    # Return only the points within the image boundaries\n",
    "    return projected_points.astype(int), mask\n",
    "\n",
    "def get_extrinsic_matrix(qvec, tvec):\n",
    "    \"\"\"\n",
    "    Create a 4x4 extrinsic matrix from quaternion and translation vector.\n",
    "    \n",
    "    Parameters:\n",
    "    - qvec: np.ndarray - Quaternion (w, x, y, z) representing rotation.\n",
    "    - tvec: np.ndarray - Translation vector (x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "    - extrinsic_matrix: np.ndarray - 4x4 extrinsic matrix.\n",
    "    \"\"\"\n",
    "    # Convert quaternion to rotation matrix\n",
    "    rotation_matrix = qvec2rotmat(qvec)\n",
    "    \n",
    "    # Create 4x4 extrinsic matrix\n",
    "    extrinsic_matrix = np.eye(4)\n",
    "    extrinsic_matrix[:3, :3] = rotation_matrix\n",
    "    extrinsic_matrix[:3, 3] = tvec\n",
    "    \n",
    "    return extrinsic_matrix\n",
    "\n",
    "\n",
    "\n",
    "def render_composite_image(points_3d, camera, extrinsics, image_path, output_path, mask_path, image_size=None, point_size=25, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Render a composite image with the projected point cloud, superimposed image, and original image,\n",
    "    and create a binary mask with dilation and closing operations applied.\n",
    "    \n",
    "    Parameters:\n",
    "    - points_3d: np.ndarray - Array of 3D points (N, 3).\n",
    "    - camera: Camera - Camera object containing intrinsics (fx, fy, cx, cy).\n",
    "    - extrinsics: np.ndarray - 4x4 matrix of extrinsics for the camera.\n",
    "    - image_path: str - Path to the original image in images_8.\n",
    "    - output_path: str - Path where the output composite image will be saved.\n",
    "    - mask_path: str - Path where the masked image will be saved.\n",
    "    - image_size: tuple - Size of the image (height, width).\n",
    "    - point_size: int - Size of points to draw on the image.\n",
    "    - alpha: float - Transparency factor for the overlay (0 = fully transparent, 1 = fully opaque).\n",
    "    \n",
    "    Returns:\n",
    "    - composite_image: np.ndarray - Composite image with the three views side-by-side.\n",
    "    \"\"\"\n",
    "    if image_size is None:\n",
    "        image_size = (camera.height, camera.width)\n",
    "    # 1. Project the 3D points onto a blank binary mask\n",
    "    projected_points, mask = project_points(points_3d, camera, extrinsics)\n",
    "    binary_mask = np.zeros((image_size[0], image_size[1]), dtype=np.uint8)\n",
    "    \n",
    "    # Draw the projected points in white on the binary mask\n",
    "    for x, y in projected_points:\n",
    "        if 0 <= x < image_size[1] and 0 <= y < image_size[0]:\n",
    "            cv2.circle(binary_mask, (x, y), point_size, 255, -1)  # White circles\n",
    "\n",
    "    # 2. Apply dilation and closing\n",
    "    dilation_kernel = np.ones((10, 10), np.uint8)\n",
    "    closing_kernel = np.ones((100, 100), np.uint8)\n",
    "    \n",
    "    dilated_mask = cv2.dilate(binary_mask, dilation_kernel, iterations=1)\n",
    "    closed_mask = cv2.morphologyEx(dilated_mask, cv2.MORPH_CLOSE, closing_kernel)\n",
    "\n",
    "    # 3. Load the actual image and apply the mask\n",
    "    actual_image = cv2.imread(image_path)\n",
    "    if actual_image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    # Resize actual image if needed to match image size\n",
    "    if actual_image.shape[:2] != image_size:\n",
    "        actual_image = cv2.resize(actual_image, (image_size[1], image_size[0]))\n",
    "\n",
    "    # Apply the closed mask to the actual image\n",
    "    masked_image = cv2.bitwise_and(actual_image, actual_image, mask=closed_mask)\n",
    "    cv2.imwrite(mask_path, masked_image)  # Save the masked image\n",
    "\n",
    "    # 4. Create an overlay image for the composite\n",
    "    overlay_layer = actual_image.copy()\n",
    "    for x, y in projected_points:\n",
    "        if 0 <= x < image_size[1] and 0 <= y < image_size[0]:\n",
    "            cv2.circle(overlay_layer, (x, y), point_size, (0, 255, 255), -1)  # Yellow circles\n",
    "\n",
    "    overlay_image = cv2.addWeighted(overlay_layer, alpha, actual_image, 1 - alpha, 0)\n",
    "\n",
    "    # 5. Concatenate the original and masked images for comparison\n",
    "    composite_image = np.hstack((cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR), overlay_image, actual_image, masked_image))\n",
    "\n",
    "    # Resize the composite image if it's too large\n",
    "    composite_image = cv2.resize(composite_image, (composite_image.shape[1] // 4, composite_image.shape[0] // 4))\n",
    "    cv2.imwrite(output_path, composite_image)\n",
    "    \n",
    "    return composite_image\n",
    "\n",
    "def project_convex_hull(hull, camera_intrinsics, extrinsics):\n",
    "    \"\"\"Project 3D convex hull vertices onto a 2D image plane.\"\"\"\n",
    "    vertices_homogeneous = np.hstack((hull.points, np.ones((hull.points.shape[0], 1))))\n",
    "    \n",
    "    if extrinsics.shape != (4, 4):\n",
    "        raise ValueError(\"Extrinsics must be a 4x4 matrix.\")\n",
    "    \n",
    "    vertices_camera = (extrinsics @ vertices_homogeneous.T).T\n",
    "    vertices_camera = vertices_camera[:, :3]\n",
    "\n",
    "    mask = vertices_camera[:, 2] > 0  # Keep vertices with positive Z\n",
    "    vertices_camera = vertices_camera[mask]\n",
    "\n",
    "    fx, fy, cx, cy = camera_intrinsics.params\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    projected_vertices = (K @ vertices_camera.T).T\n",
    "    projected_vertices = projected_vertices[:, :2] / projected_vertices[:, 2].reshape(-1, 1)\n",
    "\n",
    "    return projected_vertices.astype(int), mask\n",
    "\n",
    "def render_convex_hull_image(hull, camera, extrinsics, image_path, output_path, mask_path, image_size=None, line_color=(0, 255, 0), alpha=0.5):\n",
    "    \"\"\"Render a composite image with the projected convex hull and a mask.\"\"\"\n",
    "    if image_size is None:\n",
    "        image_size = (camera.height, camera.width)\n",
    "    projected_vertices, mask = project_convex_hull(hull, camera, extrinsics)\n",
    "    hull_image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    mask_image = np.zeros((image_size[0], image_size[1]), dtype=np.uint8)  # Mask for the convex hull\n",
    "\n",
    "    if projected_vertices.shape[0] > 3:\n",
    "        for simplex in hull.simplices:\n",
    "            if (simplex >= projected_vertices.shape[0]).any():\n",
    "                continue\n",
    "            face_vertices = projected_vertices[simplex]\n",
    "            cv2.fillConvexPoly(mask_image, face_vertices, 255)  # Fill the face on the mask\n",
    "            cv2.fillConvexPoly(hull_image, face_vertices, line_color)  # Optionally fill for visualization\n",
    "\n",
    "    cv2.imwrite(mask_path, mask_image)\t\n",
    "    # 2. Load the actual image and create an overlay (middle side)\n",
    "    actual_image = cv2.imread(image_path)\n",
    "    if actual_image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    if actual_image.shape[:2] != image_size:\n",
    "        actual_image = cv2.resize(actual_image, (image_size[1], image_size[0]))\n",
    "\n",
    "    overlay_image = cv2.addWeighted(hull_image, alpha, actual_image, 1 - alpha, 0)\n",
    "\n",
    "\n",
    "    # 3. Create the masked original image using the convex hull mask\n",
    "    masked_image = cv2.bitwise_and(actual_image, actual_image, mask=mask_image)\n",
    "\n",
    "    # 4. Concatenate the four images side-by-side, including the masked original as the fourth\n",
    "    composite_image = np.hstack((hull_image, overlay_image, actual_image, masked_image))\n",
    "\n",
    "\n",
    "    # Resize the composite image if it's too large\n",
    "    composite_image = cv2.resize(composite_image, (composite_image.shape[1]//4, composite_image.shape[0]//4))\n",
    "    cv2.imwrite(output_path, composite_image)\n",
    "    \n",
    "    return composite_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_mesh(mesh, camera_intrinsics, extrinsics):\n",
    "    \"\"\"Project 3D mesh vertices onto a 2D image plane.\"\"\"\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    vertices_homogeneous = np.hstack((vertices, np.ones((vertices.shape[0], 1))))\n",
    "    \n",
    "    if extrinsics.shape != (4, 4):\n",
    "        raise ValueError(\"Extrinsics must be a 4x4 matrix.\")\n",
    "    \n",
    "    # Transform vertices to camera space\n",
    "    vertices_camera = (extrinsics @ vertices_homogeneous.T).T\n",
    "    vertices_camera = vertices_camera[:, :3]\n",
    "\n",
    "    # Apply mask to keep only vertices with positive Z\n",
    "    mask = vertices_camera[:, 2] > 0\n",
    "    vertices_camera = vertices_camera[mask]\n",
    "\n",
    "    # Update faces to match the filtered vertices\n",
    "    valid_indices = np.where(mask)[0]\n",
    "    index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(valid_indices)}\n",
    "    faces = np.asarray(mesh.triangles)\n",
    "\n",
    "    # Remap and filter faces\n",
    "    remapped_faces = []\n",
    "    for face in faces:\n",
    "        if all(v in index_mapping for v in face):  # Keep faces with all vertices valid\n",
    "            remapped_faces.append([index_mapping[v] for v in face])\n",
    "    faces = np.array(remapped_faces)  # Convert the valid faces to a NumPy array\n",
    "\n",
    "    # Project vertices onto the 2D plane\n",
    "    fx, fy, cx, cy = camera_intrinsics.params\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    projected_vertices = (K @ vertices_camera.T).T\n",
    "    projected_vertices = projected_vertices[:, :2] / projected_vertices[:, 2].reshape(-1, 1)\n",
    "\n",
    "    return projected_vertices.astype(int), mask, faces\n",
    "\n",
    "def render_mesh_image(mesh, camera, extrinsics, image_path, output_path, mask_path, image_size=None, fill_color=(0, 255, 0), alpha=0.5):\n",
    "    \"\"\"Render a composite image with the projected mesh and a masked original image.\"\"\"\n",
    "    if image_size is None:\n",
    "        image_size = (camera.height, camera.width)\n",
    "    projected_vertices, mask, faces = project_mesh(mesh, camera, extrinsics)\n",
    "    mesh_image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    mask_image = np.zeros((image_size[0], image_size[1]), dtype=np.uint8)  # Mask for the mesh\n",
    "\n",
    "    for face in faces:\n",
    "        face_vertices = projected_vertices[face]\n",
    "        cv2.fillConvexPoly(mask_image, face_vertices, 255)  # Fill the face on the mask\n",
    "        cv2.fillConvexPoly(mesh_image, face_vertices, fill_color)  # Optionally fill for visualization\n",
    "\n",
    "    # closing the mask\n",
    "    # kernel = np.ones((50,50),np.uint8)\n",
    "    # mask_image = cv2.morphologyEx(mask_image, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imwrite(mask_path, mask_image)\n",
    "\n",
    "    # 2. Load the actual image and create an overlay (middle side)\n",
    "    actual_image = cv2.imread(image_path)\n",
    "    if actual_image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    if actual_image.shape[:2] != image_size:\n",
    "        actual_image = cv2.resize(actual_image, (image_size[1], image_size[0]))\n",
    "\n",
    "    overlay_image = cv2.addWeighted(mesh_image, alpha, actual_image, 1 - alpha, 0)\n",
    "\n",
    "    # 3. Create the masked original image using the mesh mask\n",
    "    masked_image = cv2.bitwise_and(actual_image, actual_image, mask=mask_image)\n",
    "\n",
    "    # 4. Concatenate the four images side-by-side, including the masked original as the fourth\n",
    "    composite_image = np.hstack((mesh_image, overlay_image, actual_image, masked_image))\n",
    "\n",
    "    # Resize the composite image if it's too large\n",
    "    composite_image = cv2.resize(composite_image, (composite_image.shape[1]//4, composite_image.shape[0]//4))\n",
    "    cv2.imwrite(output_path, composite_image)\n",
    "    \n",
    "    return composite_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(points, eps=None, min_samples=50):\n",
    "    if eps is None:\n",
    "        density = monte_carlo_kde(points, bandwidth=1.0)\n",
    "        mean_density = np.mean(density)\n",
    "        median_density = np.median(density)\n",
    "        eps = (1 / median_density) ** (1 / 3)\n",
    "        print(f\"Mean density: {mean_density:.2f}\")\n",
    "        print(f\"Median density: {median_density:.2f}\")\n",
    "        print(f\"Estimated epsilon: {eps:.2f}\")\n",
    "        print(f\"Estimated epsilon using mean density: {(1 / mean_density) ** (1 / 3):.2f}\")\n",
    "\n",
    "    dbscan_labels = dbscan(points, eps=eps, min_samples=min_samples)\n",
    "    unique_labels = np.unique(dbscan_labels)\n",
    "    print(f\"Number of clusters: {len(unique_labels)}\")\n",
    "    # plot clusters\n",
    "    fig = go.Figure()\n",
    "    colors = ['red', 'green', 'blue', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black']\n",
    "    # for label in unique_labels:\n",
    "    label = 0\n",
    "    color = 'gray' if label == -1 else colors[label % len(colors)]\n",
    "    # label_points = points[dbscan_labels == label]\n",
    "    # fig.add_trace(\n",
    "    #     plot_points_3d(label_points, color=color),\n",
    "    # )\n",
    "    for labels in unique_labels:\n",
    "        color = 'gray' if labels == -1 else colors[labels % len(colors)]\n",
    "        label_points = points[dbscan_labels == labels]\n",
    "        fig.add_trace(\n",
    "            plot_points_3d(label_points, color=color),\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='DBSCAN Clustering Results',\n",
    "        scene=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    # return cluster with the most points. dbscan_labels has -1 for outliers\n",
    "    cluster_sizes = np.bincount(dbscan_labels[dbscan_labels != -1])\n",
    "    largest_cluster_label = np.argmax(cluster_sizes)\n",
    "    largest_cluster_points = points[dbscan_labels == largest_cluster_label]\n",
    "    return largest_cluster_points\n",
    "\n",
    "\n",
    "def project_points_to_image(mesh, hull, camera_id, cam_extrinsics, cam_intrinsics, object_name, points):\n",
    "    camera = cam_intrinsics[camera_id] if camera_id in cam_intrinsics else cam_intrinsics[list(cam_intrinsics.keys())[0]]\n",
    "    qvec = cam_extrinsics[camera_id].qvec\n",
    "    tvec = cam_extrinsics[camera_id].tvec\n",
    "    extrinsics = get_extrinsic_matrix(qvec, tvec)\n",
    "    name = cam_extrinsics[camera_id].name\n",
    "    image_path = f\"data/{object_name}/images/{name}\"  # Path to the image in images_8\n",
    "    output_name = Path(image_path).stem\n",
    "    mask_type = \"hull\"\n",
    "    output_dir = f\"output/{object_name}/cluster/{mask_type}/mask\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"output/{object_name}/cluster/{mask_type}/{output_name}.png\"  # Output path for the rendered image\n",
    "    mask_path = f\"output/{object_name}/cluster/{mask_type}/mask/{output_name}.png\"  # Output path for the mask image\n",
    "\n",
    "\n",
    "    # Render the point cloud from the camera's viewpoint\n",
    "    # render_convex_hull_image(hull, camera, extrinsics, image_path, output_path, mask_path)\n",
    "    mask_type = \"mesh\"\n",
    "    output_dir = f\"output/{object_name}/cluster/{mask_type}/mask\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"output/{object_name}/cluster/{mask_type}/{output_name}.png\"  # Output path for the rendered image\n",
    "    mask_path = f\"output/{object_name}/cluster/{mask_type}/mask/{output_name}.png\"  # Output path for the mask image\n",
    "    render_mesh_image(mesh, camera, extrinsics, image_path, output_path, mask_path)\n",
    "    # mask_type = \"points\"\n",
    "    # output_dir = f\"output/{object_name}/cluster/{mask_type}/mask\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "    # output_path = f\"output/{object_name}/cluster/{mask_type}/{output_name}.png\"  # Output path for the rendered image\n",
    "    # mask_path = f\"output/{object_name}/cluster/{mask_type}/mask/{output_name}.png\"  # Output path for the mask image\n",
    "    # render_composite_image(points, camera, extrinsics, image_path, output_path, mask_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_object(object_name, plot=False, kde_samples=1000, min_peak_points=300, project=False, outlier_removal_eps=0.4, separate_floor=True, poisson_depth=9):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    points_original, colors, normals = read_ply(f'data/points_{object_name}.ply')\n",
    "    # plot_point_cloud(bonsai_points, bonsai_colors)\n",
    "    object_points, density = get_densest_cluster(points_original, min_peak_points, kde_samples=kde_samples, sigma=1, plot=plot)\n",
    "    pcd.points = o3d.utility.Vector3dVector(object_points)\n",
    "    o3d.io.write_point_cloud(\"output/{object_name}/cluster/new_{object_name}_density.ply\", pcd)\n",
    "    if separate_floor:\n",
    "        result = run_floor_separation(object_points, distance_threshold=None)\n",
    "        pcd.points = o3d.utility.Vector3dVector(result[\"final_points\"])\n",
    "        o3d.io.write_point_cloud(\"output/{object_name}/cluster/new_{object_name}_floorseg.ply\", pcd)\n",
    "    else:\n",
    "        result = {\"final_points\": object_points}\n",
    "    result[\"densest_cluster\"] = object_points\n",
    "    result[\"density\"] = density\n",
    "    outliers_removed = remove_outliers(result[\"final_points\"], eps=outlier_removal_eps, min_samples=50)\n",
    "    outliers_removed = remove_outliers(outliers_removed, eps=outlier_removal_eps, min_samples=200)\n",
    "    result[\"outliers_removed\"] = outliers_removed\n",
    "    if object_name[-1].isdigit():\n",
    "        object_name = object_name[:object_name.rfind(\"_\")]\n",
    "    cam_extrinsics = read_extrinsics_binary(f\"data/{object_name}/sparse/0/images.bin\")\n",
    "    cam_intrinsics = read_intrinsics_binary(f\"data/{object_name}/sparse/0/cameras.bin\")\n",
    "    \n",
    "    mesh = poisson_surface_reconstruction(outliers_removed, depth=poisson_depth)\n",
    "    plot_mesh_with_plotly(mesh, outliers_removed)\n",
    "    \n",
    "    # Write point cloud to file\n",
    "    points_path = f\"output/{object_name}/cluster/new_{object_name}_final.ply\"\n",
    "    \n",
    "    dtype = [('x', float), ('y', float), ('z', float)]\n",
    "    original_structured = np.array([tuple(p) for p in points_original], dtype=dtype)\n",
    "    outliers_structured = np.array([tuple(p) for p in outliers_removed], dtype=dtype)\n",
    "\n",
    "    indices = np.nonzero(np.in1d(original_structured, outliers_structured))[0]\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(outliers_removed)\n",
    "    if colors is not None:\n",
    "        end_colors = colors[indices]\n",
    "        pcd.colors = o3d.utility.Vector3dVector(end_colors / 255.0)\n",
    "    if normals is not None:\n",
    "        end_normals = normals[indices]\n",
    "        pcd.normals = o3d.utility.Vector3dVector(end_normals)\n",
    "\n",
    "    o3d.io.write_point_cloud(points_path, pcd)\n",
    "\n",
    "    result[\"mesh\"] = mesh\n",
    "    if project:\n",
    "        hull = ConvexHull(outliers_removed)\n",
    "        plot_convex_hull(outliers_removed, hull)\n",
    "        result[\"hull\"] = hull\n",
    "        for camera_id in cam_extrinsics:\n",
    "            project_points_to_image(mesh, hull, camera_id, cam_extrinsics, cam_intrinsics, object_name, outliers_removed)\n",
    "    return result\n",
    "    \n",
    "def write_point_cloud(points, colors, normals, indices, path):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    if colors is not None:\n",
    "        end_colors = colors[indices]\n",
    "        pcd.colors = o3d.utility.Vector3dVector(end_colors / 255.0)\n",
    "    if normals is not None:\n",
    "        end_normals = normals[indices]\n",
    "        pcd.normals = o3d.utility.Vector3dVector(end_normals)\n",
    "\n",
    "    o3d.io.write_point_cloud(path, pcd)\n",
    "\n",
    "\n",
    "def poisson_surface_reconstruction(points, depth=9):\n",
    "    # Preprocess to reduce outliers\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1.0, max_nn=30))\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=30)\n",
    "    \n",
    "    # Poisson surface reconstruction\n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=depth)\n",
    "    vertices_to_remove = densities < np.quantile(densities, 0.05)\n",
    "    mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "def plot_mesh_with_plotly(mesh, points):\n",
    "    # Extract vertices and faces from the Open3D mesh\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    faces = np.asarray(mesh.triangles)\n",
    "    \n",
    "    # Create Plotly Mesh3d plot\n",
    "    fig = go.Figure(data=[\n",
    "        go.Mesh3d(\n",
    "            x=vertices[:, 0],\n",
    "            y=vertices[:, 1],\n",
    "            z=vertices[:, 2],\n",
    "            i=faces[:, 0],\n",
    "            j=faces[:, 1],\n",
    "            k=faces[:, 2],\n",
    "            opacity=0.5,\n",
    "            color='red'\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Add original points\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(color='blue', size=2, opacity=0.6)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set the aspect ratio and scene size\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            aspectmode='data',  # Ensures the aspect ratio is proportional to the data\n",
    "            xaxis=dict(nticks=10, range=[np.min(vertices[:, 0]), np.max(vertices[:, 0])]),\n",
    "            yaxis=dict(nticks=10, range=[np.min(vertices[:, 1]), np.max(vertices[:, 1])]),\n",
    "            zaxis=dict(nticks=10, range=[np.min(vertices[:, 2]), np.max(vertices[:, 2])]),\n",
    "        ),\n",
    "        scene_camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),  # Sets an initial viewing angle\n",
    "        title=dict(text='Poisson Surface Reconstruction', x=0.5),\n",
    "        margin=dict(l=0, r=0, t=30, b=0)  # Minimizes white space around the plot\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def compute_convex_hull(points):\n",
    "    \"\"\"Compute the convex hull of a 3D point cloud.\"\"\"\n",
    "    hull = ConvexHull(points)\n",
    "    return hull\n",
    "\n",
    "def plot_convex_hull(points, hull):\n",
    "    \"\"\"Plot the convex hull with Plotly.\"\"\"\n",
    "    # Extract vertices and faces from the hull\n",
    "    vertices = points[hull.vertices]\n",
    "    faces = hull.simplices  # Indices of vertices forming each face\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=2, color='blue'),\n",
    "            name='Point Cloud'\n",
    "        ),\n",
    "        go.Mesh3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            i=faces[:, 0],\n",
    "            j=faces[:, 1],\n",
    "            k=faces[:, 2],\n",
    "            opacity=0.5,\n",
    "            color='lightgreen',\n",
    "            name='Convex Hull'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(scene=dict(aspectmode='data'), title='Convex Hull of Point Cloud')\n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "# points = np.random.rand(100, 3)  # Replace with your point cloud data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket = process_object(\"rocket\", plot=True, project=True, separate_floor=True, poisson_depth=12, kde_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycle = process_object(\"bicycle\", plot=True, project=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = poisson_surface_reconstruction(bicycle[\"outliers_removed\"], depth=9)\n",
    "plot_mesh_with_plotly(mesh, bicycle[\"outliers_removed\"])\n",
    "\n",
    "hull = compute_convex_hull(bicycle[\"outliers_removed\"])\n",
    "plot_convex_hull(bicycle[\"outliers_removed\"], hull)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonsai = process_object(\"bonsai\", plot=True, project=False, outlier_removal_eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = process_object(\"counter\", plot=True, project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garden = process_object(\"garden\", plot=True, project=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchen = process_object(\"kitchen\", plot=True, project=False, separate_floor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = process_object(\"room\", plot=False, project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump = process_object(\"stump\", plot=True, project=True, min_peak_points=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = process_object(\"plane\", plot=True, min_peak_points=100, project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def camera_position_from_extrinsics(extrinsic):\n",
    "    rotation = extrinsic[:3, :3]\n",
    "    translation = extrinsic[:3, 3]\n",
    "    position = -rotation.T @ translation\n",
    "    return position\n",
    "\n",
    "def visualize_point_cloud_with_cameras(points, camera_extrinsics):\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    geometries = [point_cloud]\n",
    "\n",
    "    for extrinsic in camera_extrinsics:\n",
    "        camera_position = camera_position_from_extrinsics(extrinsic)\n",
    "        \n",
    "        camera_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.05)\n",
    "        camera_sphere.translate(camera_position)\n",
    "        camera_sphere.paint_uniform_color([1, 0, 0]) \n",
    "        geometries.append(camera_sphere)\n",
    "        \n",
    "        camera_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2)\n",
    "        camera_frame.translate(camera_position)\n",
    "        geometries.append(camera_frame)\n",
    "\n",
    "    o3d.visualization.draw_geometries(geometries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_extrinsics = [np.eye(4), np.eye(4)]  # Replace with actual extrinsics from COLMAP\n",
    "visualize_point_cloud_with_cameras(plane[\"final_points\"], camera_extrinsics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
