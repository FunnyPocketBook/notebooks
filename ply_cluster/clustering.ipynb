{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from plyfile import PlyData\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import struct\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ply(file_path):\n",
    "    plydata = PlyData.read(file_path)\n",
    "    x = plydata['vertex']['x']\n",
    "    y = plydata['vertex']['y']\n",
    "    z = plydata['vertex']['z']\n",
    "    r = plydata['vertex']['red']\n",
    "    g = plydata['vertex']['green']\n",
    "    b = plydata['vertex']['blue']\n",
    "    colors = np.array([r, g, b]).T\n",
    "    points = np.array([x, y, z]).T\n",
    "    print(f\"Number of points: {points.shape[0]}\")\n",
    "    return points, colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Original Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_point_cloud(points, colors=None):\n",
    "    fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scatter3d'}]])\n",
    "    fig.add_trace(go.Scatter3d(x=points[:, 0], y=points[:, 1], z=points[:, 2], mode='markers', marker=dict(size=1, color=colors)), row=1, col=1)\n",
    "    fig.update_layout(width=1000, height=1000)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(points, eps=0.5, min_samples=200):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(points)\n",
    "    return labels\n",
    "\n",
    "def get_peaks(density, plot=False):\n",
    "    density_values, bin_edges = np.histogram(density, bins=100) \n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    smoothed_density = gaussian_filter1d(density_values, sigma=2)\n",
    "\n",
    "    # Step 2: Detect peaks in the smoothed histogram\n",
    "    peaks, _ = find_peaks(smoothed_density, height=20)  # Adjust height to filter out small peaks\n",
    "\n",
    "    # Step 3: Identify start and end of each peak\n",
    "    peak_boundaries = []\n",
    "    for peak in peaks:\n",
    "        start, end = peak, peak\n",
    "\n",
    "        # Move left to find where density starts increasing towards the peak\n",
    "        while start > 0 and smoothed_density[start - 1] < smoothed_density[start]:\n",
    "            start -= 1\n",
    "        \n",
    "        # Move right to find where density starts decreasing after the peak\n",
    "        while end < len(smoothed_density) - 1 and smoothed_density[end + 1] < smoothed_density[end]:\n",
    "            end += 1\n",
    "\n",
    "        peak_boundaries.append((start, end))\n",
    "\n",
    "    if plot:\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Original histogram\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers,\n",
    "            y=density_values,\n",
    "            mode='lines',\n",
    "            name=\"Original Histogram\"\n",
    "        ))\n",
    "\n",
    "        # Smoothed line\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers,\n",
    "            y=smoothed_density,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange'),\n",
    "            name=\"Smoothed Histogram\"\n",
    "        ))\n",
    "\n",
    "        # Detected peaks\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bin_centers[peaks],\n",
    "            y=smoothed_density[peaks],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red', size=10, symbol='x'),\n",
    "            name=\"Detected Peaks\"\n",
    "        ))\n",
    "\n",
    "        # Peak boundaries\n",
    "        for idx, (start, end) in enumerate(peak_boundaries):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[bin_centers[start], bin_centers[start]],\n",
    "                y=[0, max(density_values)],\n",
    "                mode='lines',\n",
    "                line=dict(color='green', dash='dash'),\n",
    "                showlegend=idx == 0,\n",
    "                name=\"Peak Start\" if idx == 0 else None\n",
    "            ))\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[bin_centers[end], bin_centers[end]],\n",
    "                y=[0, max(density_values)],\n",
    "                mode='lines',\n",
    "                line=dict(color='purple', dash='dash'),\n",
    "                showlegend=idx == 0,\n",
    "                name=\"Peak End\" if idx == 0 else None\n",
    "            ))\n",
    "\n",
    "        # Layout\n",
    "        fig.update_layout(\n",
    "            title=\"Density Histogram with Peak Detection\",\n",
    "            xaxis_title=\"Density\",\n",
    "            yaxis_title=\"Number of Points\",\n",
    "            legend=dict(\n",
    "                x=1.0,                # Position legend at the far right\n",
    "                y=1.0,                # Position legend at the top\n",
    "                xanchor='right',      # Anchor the right side of the legend box to the x position\n",
    "                yanchor='top',        # Anchor the top of the legend box to the y position\n",
    "                bgcolor='rgba(255, 255, 255, 0.5)',  # Optional: Set a semi-transparent background for better visibility\n",
    "                bordercolor='Black', # Optional: Add a border color to the legend\n",
    "                borderwidth=1         # Optional: Set the border width\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    return peak_boundaries, bin_centers\n",
    "\n",
    "\n",
    "def monte_carlo_kde(points: np.ndarray, bandwidth: float, sample_size: int = 500) -> np.ndarray:\n",
    "    sample_indices = np.random.choice(len(points), sample_size, replace=False)\n",
    "    sample_points = points[sample_indices]\n",
    "    \n",
    "    kde = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde.fit(sample_points)\n",
    "    \n",
    "    log_density = kde.score_samples(points)\n",
    "    density = np.exp(log_density)\n",
    "    \n",
    "    return density\n",
    "\n",
    "def get_densest_cluster(points, colors=None, plot=False):\n",
    "    density = monte_carlo_kde(points, bandwidth=1, sample_size=1000)  \n",
    "    peak_boundaries, bin_centers = get_peaks(density, plot=True)\n",
    "    first_peak_end_index = peak_boundaries[0][1]\n",
    "    first_peak_end = bin_centers[first_peak_end_index]\n",
    "    fig = go.Figure()\n",
    "    points = points[density > first_peak_end]\n",
    "    density = density[density > first_peak_end]\n",
    "\n",
    "    if plot:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                # color uses r, g, and b\n",
    "                color=density,\n",
    "                colorscale='Viridis',\n",
    "                colorbar=dict(title='Density'),\n",
    "                opacity=0.8\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            scene=dict(\n",
    "                xaxis_title='X',\n",
    "                yaxis_title='Y',\n",
    "                zaxis_title='Z'\n",
    "            ),\n",
    "            title=\"3D Point Cloud with Density Color-Coding\"\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    return points#, colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floor Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_surface_floor(points, distance_threshold=0.02, min_floor_points=100, max_planes=5):\n",
    "    \"\"\"Find the floor plane in a point cloud based on the largest surface area.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    largest_area = 0\n",
    "    largest_floor_points = None\n",
    "    largest_plane_model = None\n",
    "    largest_inliers = None\n",
    "\n",
    "    for _ in range(max_planes):\n",
    "        # Segment a plane using RANSAC\n",
    "        plane_model, inliers = pcd.segment_plane(\n",
    "            distance_threshold=distance_threshold,\n",
    "            ransac_n=3,\n",
    "            num_iterations=1000\n",
    "        )\n",
    "\n",
    "        # Extract inlier points for this plane\n",
    "        inlier_points = points[inliers]\n",
    "\n",
    "        # Skip if plane is too small\n",
    "        if len(inlier_points) < min_floor_points:\n",
    "            continue\n",
    "\n",
    "        # Compute convex hull for the inlier points to estimate surface area\n",
    "        inlier_pcd = o3d.geometry.PointCloud()\n",
    "        inlier_pcd.points = o3d.utility.Vector3dVector(inlier_points)\n",
    "        hull, _ = inlier_pcd.compute_convex_hull()\n",
    "\n",
    "        # Calculate the area of the convex hull\n",
    "        area = hull.get_surface_area()\n",
    "\n",
    "        # Check if this is the largest plane by area\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_floor_points = inlier_points\n",
    "            largest_plane_model = plane_model\n",
    "            largest_inliers = inliers\n",
    "\n",
    "        # Remove the detected plane from the point cloud for further iterations\n",
    "        pcd = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "    # Final checks and diagnostics\n",
    "    if largest_floor_points is None:\n",
    "        print(\"No sufficiently large planar surface found.\")\n",
    "        return None, None, None\n",
    "\n",
    "    inlier_mask = np.zeros(len(points), dtype=bool)\n",
    "    inlier_mask[largest_inliers] = True\n",
    "    non_floor_points = points[~inlier_mask]\n",
    "    \n",
    "    print(f\"Largest planar surface area: {largest_area}\")\n",
    "    print(f\"Number of floor points: {len(largest_floor_points)}\")\n",
    "    print(f\"Number of non-floor points: {len(non_floor_points)}\")\n",
    "    \n",
    "    return largest_floor_points, non_floor_points, largest_plane_model\n",
    "\n",
    "\n",
    "def find_floor_plane(points, distance_threshold=0.02, min_floor_points=100):\n",
    "    \"\"\"Find the floor plane in a point cloud.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    plane_model, inliers = pcd.segment_plane(\n",
    "        distance_threshold=distance_threshold,\n",
    "        ransac_n=3,\n",
    "        num_iterations=1000\n",
    "    )\n",
    "    \n",
    "\n",
    "    inlier_mask = np.zeros(len(points), dtype=bool)\n",
    "    inlier_mask[inliers] = True\n",
    "    \n",
    "    print(f\"Number of inlier indices: {len(inliers)}\")\n",
    "    print(f\"Number of True values in inliers: {np.sum(inliers)}\")\n",
    "    \n",
    "    floor_points = points[inlier_mask]\n",
    "    non_floor_points = points[~inlier_mask]\n",
    "    \n",
    "    print(f\"Number of floor points: {len(floor_points)}\")\n",
    "    print(f\"Number of non-floor points: {len(non_floor_points)}\")\n",
    "    \n",
    "    if len(floor_points) < min_floor_points:\n",
    "        print(f\"Warning: Found only {len(floor_points)} floor points. Might be unreliable.\")\n",
    "    \n",
    "    return floor_points, non_floor_points, plane_model\n",
    "\n",
    "\n",
    "def find_optimal_threshold(points, \n",
    "                           initial_threshold=0.01, \n",
    "                           max_threshold=0.3, \n",
    "                           iterations=50):\n",
    "    \"\"\"\n",
    "    Automatically find optimal distance threshold for floor detection without predefined floor ratio bounds.\n",
    "    The function iteratively adjusts the threshold and monitors the change in floor_ratio to determine when to stop.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : np.ndarray\n",
    "        Input point cloud as a NumPy array of shape (N, 3).\n",
    "    initial_threshold : float, default=0.02\n",
    "        Starting distance threshold value.\n",
    "    max_threshold : float, default=0.1\n",
    "        Maximum allowed threshold.\n",
    "    iterations : int, default=10\n",
    "        Maximum number of iterations for searching the optimal threshold.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    best_threshold : float\n",
    "        The optimal distance threshold found.\n",
    "    best_ratio : float\n",
    "        The ratio of floor points corresponding to the optimal threshold.\n",
    "    stats : dict\n",
    "        Dictionary containing statistics about the threshold search process.\n",
    "    \"\"\"\n",
    "    total_points = len(points)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    # Calculate point cloud statistics\n",
    "    distances = np.asarray(pcd.compute_nearest_neighbor_distance())\n",
    "    median_distance = np.median(distances)\n",
    "    \n",
    "    # Initialize threshold search\n",
    "    threshold = initial_threshold\n",
    "    best_threshold = threshold\n",
    "    best_ratio = 0\n",
    "    \n",
    "    stats = {\n",
    "        'iterations': [],\n",
    "        'thresholds': [],\n",
    "        'floor_ratios': [],\n",
    "        'improvements': [],\n",
    "        'median_distance': median_distance\n",
    "    }\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        # Segment plane with current threshold\n",
    "        plane_model, inliers = pcd.segment_plane(\n",
    "            distance_threshold=threshold,\n",
    "            ransac_n=3,\n",
    "            num_iterations=1000\n",
    "        )\n",
    "        \n",
    "        floor_ratio = len(inliers) / total_points\n",
    "        \n",
    "        # Store statistics\n",
    "        stats['iterations'].append(iteration)\n",
    "        stats['thresholds'].append(threshold)\n",
    "        stats['floor_ratios'].append(floor_ratio)        \n",
    "\n",
    "        if threshold >= max_threshold:\n",
    "            print(f\"Stopping search: Reached maximum threshold {max_threshold}\")\n",
    "            break\n",
    "\n",
    "        threshold += (max_threshold - initial_threshold) / iterations\n",
    "        threshold = min(threshold, max_threshold)\n",
    "    \n",
    "    smoothed_ratios = gaussian_filter1d(stats['floor_ratios'], sigma=3)\n",
    "    second_derivative = np.gradient(np.gradient(smoothed_ratios))\n",
    "    # best threshold is the one with the lowest second derivative\n",
    "    best_threshold = stats['thresholds'][np.argmin(second_derivative)]\n",
    "    best_ratio = stats['floor_ratios'][np.argmin(second_derivative)]\n",
    "    \n",
    "\n",
    "    # Collect final statistics\n",
    "    stats['optimal_threshold'] = best_threshold\n",
    "    stats['final_floor_ratio'] = best_ratio\n",
    "    stats['median_point_distance'] = median_distance\n",
    "    \n",
    "    return best_threshold, best_ratio, stats\n",
    "\n",
    "def find_floor_plane_auto(points, min_floor_points=100, visualize_threshold_search=False):\n",
    "    \"\"\"\n",
    "    Enhanced floor detection with automatic threshold selection.\n",
    "    \"\"\"\n",
    "    optimal_threshold, floor_ratio, stats = find_optimal_threshold(points)\n",
    "    \n",
    "    if visualize_threshold_search:\n",
    "        # Create visualization of threshold search\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Plot threshold evolution\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=stats['thresholds'],\n",
    "            name='Threshold',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='red'),\n",
    "        ))\n",
    "        \n",
    "        # Plot floor ratio evolution\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=stats['floor_ratios'],\n",
    "            name='Floor Ratio',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='cyan'),\n",
    "            yaxis='y2'\n",
    "        ))\n",
    "\n",
    "        smoothed_floor_ratio = gaussian_filter1d(stats['floor_ratios'], sigma=3)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=smoothed_floor_ratio,\n",
    "            name='Smoothed Floor Ratio',\n",
    "            mode='lines',\n",
    "            line=dict(color='blue'),\n",
    "            yaxis='y2'\n",
    "        ))\n",
    "\n",
    "\n",
    "        # plot 2nd derivative of floor ratio\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=np.gradient(np.gradient(smoothed_floor_ratio)),\n",
    "            name='2nd Derivative of Floor Ratio',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='blue'),\n",
    "        ))\n",
    "        \n",
    "        # Plot floor ratio evolution\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=stats['iterations'],\n",
    "            y=stats['improvements'],\n",
    "            name='Improvements',\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='blue'),\n",
    "            yaxis='y2'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Threshold Search Evolution',\n",
    "            xaxis_title='Iteration',\n",
    "            yaxis_title='Threshold',\n",
    "            yaxis2=dict(\n",
    "                title='Floor Ratio',\n",
    "                overlaying='y',\n",
    "                side='right'\n",
    "            )\n",
    "        )\n",
    "        fig.show()\n",
    "    \n",
    "    print(f\"Found optimal threshold: {optimal_threshold:.4f}\")\n",
    "    print(f\"Floor ratio: {floor_ratio:.2%}\")\n",
    "    print(f\"Median point distance: {stats['median_point_distance']:.4f}\")\n",
    "    \n",
    "    # Use the optimal threshold to find the floor\n",
    "    return find_floor_plane(points, distance_threshold=optimal_threshold, \n",
    "                          min_floor_points=min_floor_points)\n",
    "    # return find_largest_surface_floor(points, distance_threshold=optimal_threshold, \n",
    "    #                       min_floor_points=min_floor_points)\n",
    "\n",
    "\n",
    "def determine_model_orientation(points, plane_model):\n",
    "    \"\"\"Determine if the model is upside down relative to the floor plane.\"\"\"\n",
    "    a, b, c, d = plane_model\n",
    "    normal_vector = np.array([a, b, c])\n",
    "    \n",
    "    # Calculate signed distances to the plane\n",
    "    signed_distances = (points @ normal_vector + d)\n",
    "    \n",
    "    points_above = np.sum(signed_distances > 0)\n",
    "    points_below = np.sum(signed_distances < 0)\n",
    "    total_points = len(points)\n",
    "    \n",
    "    is_upside_down = (points_below / total_points) > 0.2\n",
    "    \n",
    "    orientation_info = {\n",
    "        \"total_points\": total_points,\n",
    "        \"points_above_floor\": points_above,\n",
    "        \"points_below_floor\": points_below,\n",
    "        \"ratio_above\": points_above / total_points,\n",
    "        \"ratio_below\": points_below / total_points,\n",
    "        \"is_upside_down\": is_upside_down,\n",
    "        \"floor_normal\": normal_vector\n",
    "    }\n",
    "    \n",
    "    return orientation_info\n",
    "\n",
    "def align_to_xy_plane(points, plane_model, orientation_info):\n",
    "    \"\"\"Align the point cloud so the floor is parallel to the XY plane and positioned at z=0.\"\"\"\n",
    "    # Extract plane parameters\n",
    "    a, b, c, d = plane_model\n",
    "    floor_normal = np.array([a, b, c])\n",
    "    \n",
    "    # If the model is upside down, flip the normal\n",
    "    if orientation_info[\"is_upside_down\"]:\n",
    "        floor_normal = -floor_normal\n",
    "    \n",
    "    # Define the target normal (Z-axis)\n",
    "    z_axis = np.array([0, 0, 1])\n",
    "    \n",
    "    # Calculate rotation required to align floor_normal with Z-axis\n",
    "    rotation_axis = np.cross(floor_normal, z_axis)\n",
    "    norm_rotation_axis = np.linalg.norm(rotation_axis)\n",
    "    \n",
    "    if norm_rotation_axis < 1e-6:\n",
    "        # The normals are already aligned or opposite\n",
    "        if np.dot(floor_normal, z_axis) < 0:\n",
    "            rotation_matrix = -np.eye(3)\n",
    "        else:\n",
    "            rotation_matrix = np.eye(3)\n",
    "    else:\n",
    "        rotation_axis /= norm_rotation_axis\n",
    "        rotation_angle = np.arccos(np.clip(np.dot(floor_normal, z_axis), -1.0, 1.0))\n",
    "        rotation = Rotation.from_rotvec(rotation_angle * rotation_axis)\n",
    "        rotation_matrix = rotation.as_matrix()\n",
    "    \n",
    "    # Rotate all points\n",
    "    rotated_points = (rotation_matrix @ points.T).T\n",
    "    \n",
    "    # Find a point on the original plane\n",
    "    plane_norm_sq = a**2 + b**2 + c**2\n",
    "    if plane_norm_sq == 0:\n",
    "        raise ValueError(\"Invalid plane model with zero normal vector.\")\n",
    "    p0 = np.array([-a * d / plane_norm_sq,\n",
    "                   -b * d / plane_norm_sq,\n",
    "                   -c * d / plane_norm_sq])\n",
    "    \n",
    "    # Rotate the point on the plane\n",
    "    p0_rotated = rotation_matrix @ p0\n",
    "    \n",
    "    # Calculate translation to bring the rotated plane to z=0\n",
    "    translation_z = -p0_rotated[2]\n",
    "    translation = np.array([0, 0, translation_z])\n",
    "    \n",
    "    # Apply translation\n",
    "    aligned_points = rotated_points + translation\n",
    "    \n",
    "    return aligned_points, rotation_matrix, translation\n",
    "\n",
    "def remove_points_below_floor(points, plane_model):\n",
    "    \"\"\"Remove points below the floor.\"\"\"\n",
    "    above_floor_mask = points[:, 2] >= 0\n",
    "    return points[above_floor_mask]\n",
    "\n",
    "def denoise_point_cloud(points, neighbors=20, std_ratio=0.1):\n",
    "    \"\"\"Denoise the point cloud using statistical outlier removal.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    cl, ind = pcd.remove_statistical_outlier(nb_neighbors=neighbors, std_ratio=std_ratio)\n",
    "    return np.asarray(pcd.points)[ind]\n",
    "\n",
    "def process_point_cloud(points, min_floor_points=500, distance_threshold=None):\n",
    "    \"\"\"Complete pipeline to process the point cloud.\"\"\"\n",
    "    result = {}\n",
    "    # 1. Find floor\n",
    "    \n",
    "    if distance_threshold is None:\n",
    "        floor_points, non_floor_points, plane_model = find_floor_plane_auto(\n",
    "            points, \n",
    "            min_floor_points=min_floor_points,\n",
    "            visualize_threshold_search=True\n",
    "        )\n",
    "    else:\n",
    "        # floor_points, non_floor_points, plane_model = find_largest_surface_floor(points, distance_threshold=distance_threshold, \n",
    "        #                   min_floor_points=min_floor_points)\n",
    "        floor_points, non_floor_points, plane_model = find_floor_plane(points, distance_threshold=distance_threshold, \n",
    "                          min_floor_points=min_floor_points)\n",
    "    result['floor_points'] = floor_points\n",
    "    result['non_floor_points'] = non_floor_points\n",
    "    result['plane_model'] = plane_model\n",
    "    \n",
    "    # 2. Determine model orientation\n",
    "    orientation_info = determine_model_orientation(\n",
    "        non_floor_points, \n",
    "        plane_model\n",
    "    )\n",
    "    \n",
    "    # 3. Align to XY plane\n",
    "    aligned_points, rotation_matrix, translation = align_to_xy_plane(\n",
    "        non_floor_points, \n",
    "        plane_model, \n",
    "        orientation_info\n",
    "    )\n",
    "    result['aligned_points'] = aligned_points\n",
    "    result['orientation_info'] = orientation_info\n",
    "    result['transformation'] = {\n",
    "        'rotation': rotation_matrix,\n",
    "        'translation': translation\n",
    "    }\n",
    "\n",
    "    \n",
    "    # 4. Remove points below floor\n",
    "    final_points = remove_points_below_floor(aligned_points, plane_model)\n",
    "    result['final_points'] = final_points\n",
    "\n",
    "    # 5. Denoise point cloud\n",
    "    denoised_points = denoise_point_cloud(final_points)\n",
    "    result['denoised_points'] = denoised_points\n",
    "\n",
    "    # 6. Denoise point cloud DBSCAN\n",
    "    dbscan_labels = dbscan(final_points, eps=0.9)\n",
    "    result['dbscan_labels'] = dbscan_labels\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Floor Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points_3d(points, color='blue', size=2, opacity=0.6):\n",
    "    \"\"\"Create a basic 3D scatter plot for points.\"\"\"\n",
    "    return go.Scatter3d(\n",
    "        x=points[:, 0], y=points[:, 1], z=points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=size,\n",
    "            color=color,\n",
    "            opacity=opacity\n",
    "        ),\n",
    "        name=f'Points ({len(points)} pts)'\n",
    "    )\n",
    "\n",
    "def plot_plane(plane_model, points, grid_size=20):\n",
    "    \"\"\"Create a surface plot for a plane within the points bounds.\"\"\"\n",
    "    a, b, c, d = plane_model\n",
    "    \n",
    "    # Get bounds from points\n",
    "    x_min, x_max = points[:, 0].min(), points[:, 0].max()\n",
    "    y_min, y_max = points[:, 1].min(), points[:, 1].max()\n",
    "    \n",
    "    # Create grid\n",
    "    x = np.linspace(x_min, x_max, grid_size)\n",
    "    y = np.linspace(y_min, y_max, grid_size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate Z values for the plane\n",
    "    Z = (-a * X - b * Y - d) / c\n",
    "    \n",
    "    return go.Surface(\n",
    "        x=X, y=Y, z=Z,\n",
    "        opacity=0.3,\n",
    "        showscale=False,\n",
    "        name='Floor plane'\n",
    "    )\n",
    "\n",
    "def visualize_floor_detection(points, floor_points, non_floor_points, plane_model):\n",
    "    \"\"\"Visualize the floor detection step.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add original points with low opacity\n",
    "    fig.add_trace(plot_points_3d(points, color='gray', opacity=0.2))\n",
    "    \n",
    "    # Add floor points\n",
    "    fig.add_trace(plot_points_3d(floor_points, color='green', opacity=0.8))\n",
    "    \n",
    "    # Add non-floor points\n",
    "    fig.add_trace(plot_points_3d(non_floor_points, color='red', opacity=0.8))\n",
    "    \n",
    "    # Add floor plane\n",
    "    fig.add_trace(plot_plane(plane_model, points))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Floor Detection Results',\n",
    "        scene=dict(\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_orientation(points, plane_model, orientation_info):\n",
    "    \"\"\"Visualize the model orientation relative to the floor.\"\"\"\n",
    "    # Split points based on their position relative to the floor\n",
    "    a, b, c, d = plane_model\n",
    "    signed_distances = (points @ np.array([a, b, c]) + d)\n",
    "    \n",
    "    points_above = points[signed_distances > 0]\n",
    "    points_below = points[signed_distances < 0]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add points above floor\n",
    "    if len(points_above) > 0:\n",
    "        fig.add_trace(plot_points_3d(points_above, color='blue', opacity=0.8))\n",
    "    \n",
    "    # Add points below floor\n",
    "    if len(points_below) > 0:\n",
    "        fig.add_trace(plot_points_3d(points_below, color='red', opacity=0.8))\n",
    "    \n",
    "    # Add floor plane\n",
    "    fig.add_trace(plot_plane(plane_model, points))\n",
    "    \n",
    "    # Add floor normal vector at center of points\n",
    "    center = points.mean(axis=0)\n",
    "    normal = orientation_info['floor_normal'] * (points.max() - points.min()).mean() * 0.2\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[center[0], center[0] + normal[0]],\n",
    "        y=[center[1], center[1] + normal[1]],\n",
    "        z=[center[2], center[2] + normal[2]],\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='black', width=5),\n",
    "        name='Floor normal'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Model Orientation (Upside down: {orientation_info['is_upside_down']})\",\n",
    "        scene=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_alignment(original_points, aligned_points):\n",
    "    \"\"\"Visualize the alignment transformation.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
    "        subplot_titles=('Original Points', 'Aligned Points')\n",
    "    )\n",
    "    \n",
    "    # Original points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(original_points, color='blue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Aligned points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(aligned_points, color='green'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Point Cloud Alignment Results',\n",
    "        scene=dict(aspectmode='data'),\n",
    "        scene2=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_final_result(original_points, final_points):\n",
    "    \"\"\"Visualize the original vs final processed point cloud.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
    "        subplot_titles=('Original Point Cloud', 'Processed Point Cloud')\n",
    "    )\n",
    "    \n",
    "    # Original points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(original_points, color='blue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Final points\n",
    "    fig.add_trace(\n",
    "        plot_points_3d(final_points, color='green'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Final Processing Results',\n",
    "        scene=dict(aspectmode='data'),\n",
    "        scene2=dict(aspectmode='data'),\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_complete_pipeline(result_dict):\n",
    "    \"\"\"Visualize all steps of the pipeline in a single figure.\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        specs=[[{'type': 'scene'}, {'type': 'scene'}],\n",
    "               [{'type': 'scene'}, {'type': 'scene'}],\n",
    "               [{'type': 'scene'}, {'type': 'scene'}]],\n",
    "        subplot_titles=(\n",
    "            'Floor Detection',\n",
    "            'Orientation Analysis',\n",
    "            'Alignment Result',\n",
    "            'Final Result',\n",
    "            'Denoised Result Statistical Outlier',\n",
    "            'Denoised Result DBSCAN'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 1. Floor Detection\n",
    "    floor_trace = plot_points_3d(result_dict['floor_points'], color='green')\n",
    "    fig.add_trace(floor_trace, row=1, col=1)\n",
    "    \n",
    "    # 2. Orientation\n",
    "    above_below_trace = plot_points_3d(result_dict['aligned_points'], color='blue')\n",
    "    fig.add_trace(above_below_trace, row=1, col=2)\n",
    "    \n",
    "    # 3. Alignment\n",
    "    aligned_trace = plot_points_3d(result_dict['aligned_points'], color='orange')\n",
    "    fig.add_trace(aligned_trace, row=2, col=1)\n",
    "    \n",
    "    # 4. Final Result\n",
    "    final_trace = plot_points_3d(result_dict['final_points'], color='red')\n",
    "    fig.add_trace(final_trace, row=2, col=2)\n",
    "\n",
    "    # 5. Denoised Result Statistical Outlier\n",
    "    denoised_trace = plot_points_3d(result_dict['denoised_points'], color='purple')\n",
    "    fig.add_trace(denoised_trace, row=3, col=1)\n",
    "\n",
    "    # 6. Denoised Result DBSCAN\n",
    "    # INSERT CODE HERE\n",
    "    dbscan_labels = result_dict[\"dbscan_labels\"]\n",
    "    unique_labels = np.unique(dbscan_labels)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        color = 'gray' if label == -1 else f\"rgba({np.random.randint(0,255)},{np.random.randint(0,255)},{np.random.randint(0,255)},0.6)\"\n",
    "        label_points = result_dict['final_points'][dbscan_labels == label]\n",
    "        fig.add_trace(\n",
    "            plot_points_3d(label_points, color=color),\n",
    "            row=3, col=2\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        title='Complete Pipeline Visualization',\n",
    "        height=1000,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (C) 2023, Inria\n",
    "# GRAPHDECO research group, https://team.inria.fr/graphdeco\n",
    "# All rights reserved.\n",
    "#\n",
    "# This software is free for non-commercial, research and evaluation use \n",
    "# under the terms of the LICENSE.md file.\n",
    "#\n",
    "# For inquiries contact  george.drettakis@inria.fr\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import struct\n",
    "\n",
    "CameraModel = collections.namedtuple(\n",
    "    \"CameraModel\", [\"model_id\", \"model_name\", \"num_params\"])\n",
    "Camera = collections.namedtuple(\n",
    "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"])\n",
    "BaseImage = collections.namedtuple(\n",
    "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
    "Point3D = collections.namedtuple(\n",
    "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"])\n",
    "CAMERA_MODELS = {\n",
    "    CameraModel(model_id=0, model_name=\"SIMPLE_PINHOLE\", num_params=3),\n",
    "    CameraModel(model_id=1, model_name=\"PINHOLE\", num_params=4),\n",
    "    CameraModel(model_id=2, model_name=\"SIMPLE_RADIAL\", num_params=4),\n",
    "    CameraModel(model_id=3, model_name=\"RADIAL\", num_params=5),\n",
    "    CameraModel(model_id=4, model_name=\"OPENCV\", num_params=8),\n",
    "    CameraModel(model_id=5, model_name=\"OPENCV_FISHEYE\", num_params=8),\n",
    "    CameraModel(model_id=6, model_name=\"FULL_OPENCV\", num_params=12),\n",
    "    CameraModel(model_id=7, model_name=\"FOV\", num_params=5),\n",
    "    CameraModel(model_id=8, model_name=\"SIMPLE_RADIAL_FISHEYE\", num_params=4),\n",
    "    CameraModel(model_id=9, model_name=\"RADIAL_FISHEYE\", num_params=5),\n",
    "    CameraModel(model_id=10, model_name=\"THIN_PRISM_FISHEYE\", num_params=12)\n",
    "}\n",
    "CAMERA_MODEL_IDS = dict([(camera_model.model_id, camera_model)\n",
    "                         for camera_model in CAMERA_MODELS])\n",
    "CAMERA_MODEL_NAMES = dict([(camera_model.model_name, camera_model)\n",
    "                           for camera_model in CAMERA_MODELS])\n",
    "\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "def rotmat2qvec(R):\n",
    "    Rxx, Ryx, Rzx, Rxy, Ryy, Rzy, Rxz, Ryz, Rzz = R.flat\n",
    "    K = np.array([\n",
    "        [Rxx - Ryy - Rzz, 0, 0, 0],\n",
    "        [Ryx + Rxy, Ryy - Rxx - Rzz, 0, 0],\n",
    "        [Rzx + Rxz, Rzy + Ryz, Rzz - Rxx - Ryy, 0],\n",
    "        [Ryz - Rzy, Rzx - Rxz, Rxy - Ryx, Rxx + Ryy + Rzz]]) / 3.0\n",
    "    eigvals, eigvecs = np.linalg.eigh(K)\n",
    "    qvec = eigvecs[[3, 0, 1, 2], np.argmax(eigvals)]\n",
    "    if qvec[0] < 0:\n",
    "        qvec *= -1\n",
    "    return qvec\n",
    "\n",
    "class Image(BaseImage):\n",
    "    def qvec2rotmat(self):\n",
    "        return qvec2rotmat(self.qvec)\n",
    "\n",
    "def read_next_bytes(fid, num_bytes, format_char_sequence, endian_character=\"<\"):\n",
    "    \"\"\"Read and unpack the next bytes from a binary file.\n",
    "    :param fid:\n",
    "    :param num_bytes: Sum of combination of {2, 4, 8}, e.g. 2, 6, 16, 30, etc.\n",
    "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
    "    :param endian_character: Any of {@, =, <, >, !}\n",
    "    :return: Tuple of read and unpacked values.\n",
    "    \"\"\"\n",
    "    data = fid.read(num_bytes)\n",
    "    return struct.unpack(endian_character + format_char_sequence, data)\n",
    "\n",
    "def read_points3D_text(path):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DText(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DText(const std::string& path)\n",
    "    \"\"\"\n",
    "    xyzs = None\n",
    "    rgbs = None\n",
    "    errors = None\n",
    "    num_points = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                num_points += 1\n",
    "\n",
    "\n",
    "    xyzs = np.empty((num_points, 3))\n",
    "    rgbs = np.empty((num_points, 3))\n",
    "    errors = np.empty((num_points, 1))\n",
    "    count = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
    "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
    "                error = np.array(float(elems[7]))\n",
    "                xyzs[count] = xyz\n",
    "                rgbs[count] = rgb\n",
    "                errors[count] = error\n",
    "                count += 1\n",
    "\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_points3D_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DBinary(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_points = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "\n",
    "        xyzs = np.empty((num_points, 3))\n",
    "        rgbs = np.empty((num_points, 3))\n",
    "        errors = np.empty((num_points, 1))\n",
    "\n",
    "        for p_id in range(num_points):\n",
    "            binary_point_line_properties = read_next_bytes(\n",
    "                fid, num_bytes=43, format_char_sequence=\"QdddBBBd\")\n",
    "            xyz = np.array(binary_point_line_properties[1:4])\n",
    "            rgb = np.array(binary_point_line_properties[4:7])\n",
    "            error = np.array(binary_point_line_properties[7])\n",
    "            track_length = read_next_bytes(\n",
    "                fid, num_bytes=8, format_char_sequence=\"Q\")[0]\n",
    "            track_elems = read_next_bytes(\n",
    "                fid, num_bytes=8*track_length,\n",
    "                format_char_sequence=\"ii\"*track_length)\n",
    "            xyzs[p_id] = xyz\n",
    "            rgbs[p_id] = rgb\n",
    "            errors[p_id] = error\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_intrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                camera_id = int(elems[0])\n",
    "                model = elems[1]\n",
    "                assert model == \"PINHOLE\", \"While the loader support other types, the rest of the code assumes PINHOLE\"\n",
    "                width = int(elems[2])\n",
    "                height = int(elems[3])\n",
    "                params = np.array(tuple(map(float, elems[4:])))\n",
    "                cameras[camera_id] = Camera(id=camera_id, model=model,\n",
    "                                            width=width, height=height,\n",
    "                                            params=params)\n",
    "    return cameras\n",
    "\n",
    "def read_extrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadImagesBinary(const std::string& path)\n",
    "        void Reconstruction::WriteImagesBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_reg_images = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_reg_images):\n",
    "            binary_image_properties = read_next_bytes(\n",
    "                fid, num_bytes=64, format_char_sequence=\"idddddddi\")\n",
    "            image_id = binary_image_properties[0]\n",
    "            qvec = np.array(binary_image_properties[1:5])\n",
    "            tvec = np.array(binary_image_properties[5:8])\n",
    "            camera_id = binary_image_properties[8]\n",
    "            image_name = \"\"\n",
    "            current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            while current_char != b\"\\x00\":   # look for the ASCII 0 entry\n",
    "                image_name += current_char.decode(\"utf-8\")\n",
    "                current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            num_points2D = read_next_bytes(fid, num_bytes=8,\n",
    "                                           format_char_sequence=\"Q\")[0]\n",
    "            x_y_id_s = read_next_bytes(fid, num_bytes=24*num_points2D,\n",
    "                                       format_char_sequence=\"ddq\"*num_points2D)\n",
    "            xys = np.column_stack([tuple(map(float, x_y_id_s[0::3])),\n",
    "                                   tuple(map(float, x_y_id_s[1::3]))])\n",
    "            point3D_ids = np.array(tuple(map(int, x_y_id_s[2::3])))\n",
    "            images[image_id] = Image(\n",
    "                id=image_id, qvec=qvec, tvec=tvec,\n",
    "                camera_id=camera_id, name=image_name,\n",
    "                xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_intrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::WriteCamerasBinary(const std::string& path)\n",
    "        void Reconstruction::ReadCamerasBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_cameras = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_cameras):\n",
    "            camera_properties = read_next_bytes(\n",
    "                fid, num_bytes=24, format_char_sequence=\"iiQQ\")\n",
    "            camera_id = camera_properties[0]\n",
    "            model_id = camera_properties[1]\n",
    "            model_name = CAMERA_MODEL_IDS[camera_properties[1]].model_name\n",
    "            width = camera_properties[2]\n",
    "            height = camera_properties[3]\n",
    "            num_params = CAMERA_MODEL_IDS[model_id].num_params\n",
    "            params = read_next_bytes(fid, num_bytes=8*num_params,\n",
    "                                     format_char_sequence=\"d\"*num_params)\n",
    "            cameras[camera_id] = Camera(id=camera_id,\n",
    "                                        model=model_name,\n",
    "                                        width=width,\n",
    "                                        height=height,\n",
    "                                        params=np.array(params))\n",
    "        assert len(cameras) == num_cameras\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def read_extrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
    "                                       tuple(map(float, elems[1::3]))])\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id, qvec=qvec, tvec=tvec,\n",
    "                    camera_id=camera_id, name=image_name,\n",
    "                    xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_colmap_bin_array(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_dense.py\n",
    "\n",
    "    :param path: path to the colmap binary file.\n",
    "    :return: nd array with the floating point values in the value\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as fid:\n",
    "        width, height, channels = np.genfromtxt(fid, delimiter=\"&\", max_rows=1,\n",
    "                                                usecols=(0, 1, 2), dtype=int)\n",
    "        fid.seek(0)\n",
    "        num_delimiter = 0\n",
    "        byte = fid.read(1)\n",
    "        while True:\n",
    "            if byte == b\"&\":\n",
    "                num_delimiter += 1\n",
    "                if num_delimiter >= 3:\n",
    "                    break\n",
    "            byte = fid.read(1)\n",
    "        array = np.fromfile(fid, np.float32)\n",
    "    array = array.reshape((width, height, channels), order=\"F\")\n",
    "    return np.transpose(array, (1, 0, 2)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Floor Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_floor_separation(points, min_floor_points=500, distance_threshold=None):\n",
    "    result = process_point_cloud(points, min_floor_points, distance_threshold)\n",
    "    print(f\"Floor points: {len(result['floor_points'])}, Non-floor points: {len(result['non_floor_points'])}\")\n",
    "    # Visualize individual steps\n",
    "    fig_floor = visualize_floor_detection(\n",
    "        points, \n",
    "        result['floor_points'], \n",
    "        result['non_floor_points'], \n",
    "        result['plane_model']\n",
    "    )\n",
    "    fig_floor.show()\n",
    "\n",
    "    fig_orientation = visualize_orientation(\n",
    "        points, \n",
    "        result['plane_model'], \n",
    "        result['orientation_info']\n",
    "    )\n",
    "    fig_orientation.show()\n",
    "\n",
    "    fig_alignment = visualize_alignment(\n",
    "        points, \n",
    "        result['aligned_points']\n",
    "    )\n",
    "    fig_alignment.show()\n",
    "\n",
    "    fig_final = visualize_final_result(\n",
    "        points, \n",
    "        result['final_points']\n",
    "    )\n",
    "    fig_final.show()\n",
    "\n",
    "    # # Or visualize everything at once\n",
    "    fig_complete = visualize_complete_pipeline(result)\n",
    "    fig_complete.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(points_3d, camera_intrinsics, extrinsics):\n",
    "    \"\"\"\n",
    "    Project 3D points onto a 2D image plane using camera intrinsics and extrinsics.\n",
    "    \n",
    "    Parameters:\n",
    "    - points_3d: np.ndarray - Array of 3D points (N, 3).\n",
    "    - camera_intrinsics: Camera - The camera intrinsics (e.g., focal length, principal point).\n",
    "    - extrinsics: np.ndarray - 4x4 extrinsic matrix (rotation and translation).\n",
    "\n",
    "    Returns:\n",
    "    - projected_points: np.ndarray - 2D projected points in image space.\n",
    "    - mask: np.ndarray - Boolean array indicating which points are in front of the camera.\n",
    "    \"\"\"\n",
    "    # Convert points to homogeneous coordinates\n",
    "    points_homogeneous = np.hstack((points_3d, np.ones((points_3d.shape[0], 1))))\n",
    "    \n",
    "    # Transform 3D points to the camera coordinate system\n",
    "    points_camera = (extrinsics @ points_homogeneous.T).T\n",
    "    points_camera = points_camera[:, :3]\n",
    "\n",
    "    # Filter points in front of the camera\n",
    "    mask = points_camera[:, 2] > 0  # Keep points with positive Z\n",
    "    points_camera = points_camera[mask]\n",
    "\n",
    "    # Create intrinsic matrix\n",
    "    fx, fy, cx, cy = camera_intrinsics.params  # Assuming Pinhole model (fx, fy, cx, cy)\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    # Project points onto the image plane\n",
    "    projected_points = (K @ points_camera.T).T\n",
    "    projected_points = projected_points[:, :2] / projected_points[:, 2].reshape(-1, 1)\n",
    "\n",
    "\n",
    "    # Return only the points within the image boundaries\n",
    "    return projected_points.astype(int), mask\n",
    "\n",
    "def get_extrinsic_matrix(qvec, tvec):\n",
    "    \"\"\"\n",
    "    Create a 4x4 extrinsic matrix from quaternion and translation vector.\n",
    "    \n",
    "    Parameters:\n",
    "    - qvec: np.ndarray - Quaternion (w, x, y, z) representing rotation.\n",
    "    - tvec: np.ndarray - Translation vector (x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "    - extrinsic_matrix: np.ndarray - 4x4 extrinsic matrix.\n",
    "    \"\"\"\n",
    "    # Convert quaternion to rotation matrix\n",
    "    rotation_matrix = qvec2rotmat(qvec)\n",
    "    \n",
    "    # Create 4x4 extrinsic matrix\n",
    "    extrinsic_matrix = np.eye(4)\n",
    "    extrinsic_matrix[:3, :3] = rotation_matrix\n",
    "    extrinsic_matrix[:3, 3] = tvec\n",
    "    \n",
    "    return extrinsic_matrix\n",
    "\n",
    "\n",
    "\n",
    "def render_composite_image(points_3d, camera, extrinsics, image_path, output_path, image_size=(3300, 4978), point_size=15, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Render a composite image with the projected point cloud, superimposed image, and original image.\n",
    "    \n",
    "    Parameters:\n",
    "    - points_3d: np.ndarray - Array of 3D points (N, 3).\n",
    "    - camera: Camera - Camera object containing intrinsics (fx, fy, cx, cy).\n",
    "    - extrinsics: np.ndarray - 4x4 matrix of extrinsics for the camera.\n",
    "    - image_path: str - Path to the original image in images_8.\n",
    "    - output_path: str - Path where the output composite image will be saved.\n",
    "    - image_size: tuple - Size of the image (height, width).\n",
    "    - point_size: int - Size of points to draw on the image.\n",
    "    - alpha: float - Transparency factor for the overlay (0 = fully transparent, 1 = fully opaque).\n",
    "    \n",
    "    Returns:\n",
    "    - composite_image: np.ndarray - Composite image with the three views side-by-side.\n",
    "    \"\"\"\n",
    "    # 1. Project the 3D points onto a blank image (left side)\n",
    "    projected_points, mask = project_points(points_3d, camera, extrinsics)\n",
    "    point_cloud_image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    # Draw the projected points in white on a blank image\n",
    "    for x, y in projected_points:\n",
    "        if 0 <= x < image_size[1] and 0 <= y < image_size[0]:\n",
    "            cv2.circle(point_cloud_image, (x, y), point_size, (255, 255, 255), -1)\n",
    "\n",
    "    # 2. Load the actual image and create an overlay (middle side)\n",
    "    actual_image = cv2.imread(image_path)\n",
    "    if actual_image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    # Resize actual image if needed to match image size\n",
    "    if actual_image.shape[:2] != image_size:\n",
    "        actual_image = cv2.resize(actual_image, (image_size[1], image_size[0]))\n",
    "\n",
    "    # Create a separate overlay layer for the circles\n",
    "    overlay_layer = actual_image.copy()\n",
    "    for x, y in projected_points:\n",
    "        if 0 <= x < image_size[1] and 0 <= y < image_size[0]:\n",
    "            cv2.circle(overlay_layer, (x, y), point_size, (0, 255, 255), -1)  # Yellow circles\n",
    "\n",
    "    # Blend the overlay layer with the actual image to create transparency\n",
    "    overlay_image = cv2.addWeighted(overlay_layer, alpha, actual_image, 1 - alpha, 0)\n",
    "\n",
    "    # 3. Concatenate the three images side-by-side\n",
    "    composite_image = np.hstack((point_cloud_image, overlay_image, actual_image))\n",
    "\n",
    "    # resize the composite image to a reasonable size. Right now it's 14934 x 3300 pixels, which is 30MB\n",
    "    # make it 1/4 of the size\n",
    "    composite_image = cv2.resize(composite_image, (composite_image.shape[1]//4, composite_image.shape[0]//4))\n",
    "    # Save or return the composite image\n",
    "    cv2.imwrite(output_path, composite_image)\n",
    "    print(f\"Composite image saved to {output_path}\")\n",
    "    \n",
    "    return composite_image\n",
    "\n",
    "\n",
    "def project_points_to_image(camera_id, object_name, points):\n",
    "    camera = cam_intrinsics[1]\n",
    "    qvec = cam_extrinsics[camera_id].qvec\n",
    "    tvec = cam_extrinsics[camera_id].tvec\n",
    "    extrinsics = get_extrinsic_matrix(qvec, tvec)\n",
    "    name = cam_extrinsics[camera_id].name\n",
    "    image_path = f\"data/{object_name}/images_8/{name}\"  # Path to the image in images_8\n",
    "    output_name = Path(image_path).stem\n",
    "    output_path = f\"output/{object_name}/cluster/{output_name}.png\"  # Output path for the rendered image\n",
    "\n",
    "    # Generate or load a point cloud (replace with your point cloud data)\n",
    "\n",
    "    # Render the point cloud from the camera's viewpoint\n",
    "    render_composite_image(points, camera, extrinsics, image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicycle_points, bicycle_colors = read_ply('data/points_bicycle.ply')\n",
    "# plot_point_cloud(bicycle_points, bicycle_colors)\n",
    "bicycle = get_densest_cluster(bicycle_points, plot=True)\n",
    "run_floor_separation(bicycle)\n",
    "cam_extrinsics = read_extrinsics_binary(\"data/images.bin\")\n",
    "cam_intrinsics = read_intrinsics_binary(\"data/cameras.bin\")\n",
    "\n",
    "for camera_id in cam_extrinsics:\n",
    "    project_points_to_image(camera_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonsai_points, bonsai_colors = read_ply('data/points_bonsai.ply')\n",
    "# plot_point_cloud(bonsai_points, bonsai_colors)\n",
    "bonsai = get_densest_cluster(bonsai_points, plot=True)\n",
    "run_floor_separation(bonsai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_points, counter_colors = read_ply('data/points_counter.ply')\n",
    "# plot_point_cloud(counter_points, counter_colors)\n",
    "counter = get_densest_cluster(counter_points, plot=True)\n",
    "run_floor_separation(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garden_points, garden_colors = read_ply('data/points_garden.ply')\n",
    "# plot_point_cloud(garden_points, garden_colors)\n",
    "garden = get_densest_cluster(garden_points, plot=True)\n",
    "run_floor_separation(garden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchen_points, kitchen_colors = read_ply('data/points_kitchen.ply')\n",
    "# plot_point_cloud(kitchen_points, kitchen_colors)\n",
    "kitchen = get_densest_cluster(kitchen_points, plot=True)\n",
    "run_floor_separation(kitchen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_points, room_colors = read_ply('data/points_room.ply')\n",
    "# plot_point_cloud(room_points, room_colors)\n",
    "room = get_densest_cluster(room_points, plot=True)\n",
    "run_floor_separation(room)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump_points, stump_colors = read_ply('data/points_stump.ply')\n",
    "# plot_point_cloud(counter_points, stump_colors)\n",
    "stump = get_densest_cluster(stump_points, plot=True)\n",
    "stump_result = run_floor_separation(stump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump_points, stump_colors = read_ply('data/points_bass.ply')\n",
    "# plot_point_cloud(counter_points, stump_colors)\n",
    "stump = get_densest_cluster(stump_points, plot=True)\n",
    "run_floor_separation(stump)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
